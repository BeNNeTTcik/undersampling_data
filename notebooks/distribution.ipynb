{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datacompy\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "\n",
    "# narzedzia\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    cross_val_predict,\n",
    "    learning_curve,\n",
    "    RepeatedStratifiedKFold,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from scipy import stats\n",
    "from joblib import dump, load\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# modele\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# methods\n",
    "from imblearn.under_sampling import ClusterCentroids, NearMiss\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from ctgan import CTGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_NM_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\mix_NM_data.csv\")\n",
    "mix_KM_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\mix_KM_data.csv\")\n",
    "mix_CC_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\mix_CC_data.csv\")\n",
    "\n",
    "borderline_NM_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\borderline_NM_data.csv\")\n",
    "borderline_KM_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\borderline_KM_data.csv\")\n",
    "borderline_CC_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\borderline_CC_data.csv\")\n",
    "\n",
    "smote_NM_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\smote_NM_data.csv\")\n",
    "smote_KM_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\smote_KM_data.csv\")\n",
    "smote_CC_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\smote_CC_data.csv\")\n",
    "\n",
    "GAN_NM_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\GAN_NM_data.csv\")\n",
    "GAN_KM_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\GAN_KM_data.csv\")\n",
    "GAN_CC_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\GAN_CC_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data[\"mix_NM_data\"] = mix_NM_data\n",
    "data[\"mix_KM_data\"] = mix_KM_data\n",
    "data[\"mix_CC_data\"] = mix_CC_data\n",
    "data[\"borderline_NM_data\"] = borderline_NM_data\n",
    "data[\"borderline_KM_data\"] = borderline_KM_data\n",
    "data[\"borderline_CC_data\"] = borderline_CC_data\n",
    "data[\"smote_NM_data\"] = smote_NM_data\n",
    "data[\"smote_KM_data\"] = smote_KM_data\n",
    "data[\"smote_CC_data\"] = smote_CC_data\n",
    "data[\"GAN_NM_data\"] = GAN_NM_data\n",
    "data[\"GAN_KM_data\"] = GAN_KM_data\n",
    "data[\"GAN_CC_data\"] = GAN_CC_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribiution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: mix_NM_data\n",
      "Distribiution:\n",
      "source\n",
      "original            54.635762\n",
      "borderline smote    26.158940\n",
      "smote               16.887417\n",
      "gan                  2.317881\n",
      "Name: mix_NM_data, dtype: float64\n",
      "Data: mix_KM_data\n",
      "Distribiution:\n",
      "source\n",
      "centroid    100.0\n",
      "Name: mix_KM_data, dtype: float64\n",
      "Data: mix_CC_data\n",
      "Distribiution:\n",
      "source\n",
      "original            50.662252\n",
      "gan                 25.165563\n",
      "centroid            19.205298\n",
      "borderline smote     2.980132\n",
      "smote                1.986755\n",
      "Name: mix_CC_data, dtype: float64\n",
      "Data: borderline_NM_data\n",
      "Distribiution:\n",
      "source\n",
      "original            52.317881\n",
      "borderline smote    47.682119\n",
      "Name: borderline_NM_data, dtype: float64\n",
      "Data: borderline_KM_data\n",
      "Distribiution:\n",
      "source\n",
      "centroid    100.0\n",
      "Name: borderline_KM_data, dtype: float64\n",
      "Data: borderline_CC_data\n",
      "Distribiution:\n",
      "source\n",
      "original            57.947020\n",
      "centroid            24.834437\n",
      "borderline smote    17.218543\n",
      "Name: borderline_CC_data, dtype: float64\n",
      "Data: smote_NM_data\n",
      "Distribiution:\n",
      "source\n",
      "original    54.635762\n",
      "smote       45.364238\n",
      "Name: smote_NM_data, dtype: float64\n",
      "Data: smote_KM_data\n",
      "Distribiution:\n",
      "source\n",
      "centroid    100.0\n",
      "Name: smote_KM_data, dtype: float64\n",
      "Data: smote_CC_data\n",
      "Distribiution:\n",
      "source\n",
      "original    51.986755\n",
      "centroid    35.099338\n",
      "smote       12.913907\n",
      "Name: smote_CC_data, dtype: float64\n",
      "Data: GAN_NM_data\n",
      "Distribiution:\n",
      "source\n",
      "original    58.940397\n",
      "gan         41.059603\n",
      "Name: GAN_NM_data, dtype: float64\n",
      "Data: GAN_KM_data\n",
      "Distribiution:\n",
      "source\n",
      "centroid    100.0\n",
      "Name: GAN_KM_data, dtype: float64\n",
      "Data: GAN_CC_data\n",
      "Distribiution:\n",
      "source\n",
      "original    50.662252\n",
      "centroid    37.748344\n",
      "gan         11.589404\n",
      "Name: GAN_CC_data, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' collect = collect.merge(sum_data_NM, on=collect.columns.tolist(), how=\\'left\\', indicator=True)\\ncollect = collect.drop(columns=[\"_merge\"])\\ncollect = collect.drop_duplicates()\\nprint(collect)\\nprint(collect[\"source\"].value_counts()) '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_xlsx = \"D:\\\\ml\\\\undersampling_data\\\\reports\\\\ssh\\\\distribiution\\\\distribiution.xlsx\"\n",
    "output_txt = \"D:\\\\ml\\\\undersampling_data\\\\reports\\\\ssh\\\\distribiution\\\\distribiution.txt\"\n",
    "\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "for name, data in data.items():\n",
    "    \n",
    "    data = pd.DataFrame(data)\n",
    "    results = data[\"source\"].value_counts(normalize=True) * 100\n",
    "    results.name = name\n",
    "    print(f\"Data: {name}\")\n",
    "    print(f\"Distribiution:\\n{results}\")\n",
    "    \n",
    "    with open(output_txt, \"a\") as f:\n",
    "        f.write(f\"Data: {name}\\n\")\n",
    "        f.write(f\"Distribiution:\\n{results}\\n\\n\")\n",
    "    \n",
    "    # Append results to the combined DataFrame\n",
    "    all_results = pd.concat([all_results, results], axis=1)\n",
    "    \n",
    "with pd.ExcelWriter(output_xlsx, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    all_results.to_excel(writer, sheet_name='Distribution', index=True)\n",
    "    \n",
    "    \n",
    "#compare collect and sum_data_NM and copy column source to collect, if rows are the same\n",
    "\"\"\" collect = collect.merge(sum_data_NM, on=collect.columns.tolist(), how='left', indicator=True)\n",
    "collect = collect.drop(columns=[\"_merge\"])\n",
    "collect = collect.drop_duplicates()\n",
    "print(collect)\n",
    "print(collect[\"source\"].value_counts()) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
