{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datacompy\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "# narzedzia\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    cross_val_predict,\n",
    "    learning_curve,\n",
    "    RepeatedStratifiedKFold,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from scipy import stats\n",
    "from joblib import dump, load\n",
    "\n",
    "# modele\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# methods\n",
    "from imblearn.under_sampling import ClusterCentroids, NearMiss\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from ctgan import CTGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #undersampling prepare data //mixed data (gan, brdsmote, smote)\\ncc_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\clustercentroids_data.csv\")\\nif_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\isolationforest_data.csv\")\\nnm_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\nearmiss_data.csv\")\\nmedian_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\median_data.csv\")\\nlof_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\localoutlierfactor_data.csv\") '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oversampling data\n",
    "original_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\original_data.csv\")    \n",
    "original_data = original_data.drop(columns=[\"Unnamed: 0\"])\n",
    "smote_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\smote_data.csv\")\n",
    "GAN_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\GAN_data.csv\")\n",
    "borderline_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\borderline_data.csv\")\n",
    "smote2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\smote3_data.csv\")\n",
    "GAN2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\GAN3_data.csv\")    \n",
    "borderline2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\borderline3_data.csv\")\n",
    "\n",
    "# test data\n",
    "X_test = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\test\\\\X_test.csv\")\n",
    "y_test = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\test\\\\y_test.csv\")\n",
    "\n",
    "\"\"\" #undersampling prepare data //mixed data (gan, brdsmote, smote)\n",
    "cc_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\clustercentroids_data.csv\")\n",
    "if_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\isolationforest_data.csv\")\n",
    "nm_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\nearmiss_data.csv\")\n",
    "median_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\median_data.csv\")\n",
    "lof_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\localoutlierfactor_data.csv\") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    151\n",
      "1     46\n",
      "Name: count, dtype: int64\n",
      "197\n",
      "Before undersampling: 105\n",
      "After number of samples: 302\n"
     ]
    }
   ],
   "source": [
    "print(original_data[\"target\"].value_counts())\n",
    "count1=original_data[\"target\"].value_counts().sum()\n",
    "print(count1)\n",
    "count2=abs((original_data['target']==0).sum() - (original_data['target']==1).sum())\n",
    "print(f\"Before undersampling: {count2}\")\n",
    "print(f\"After number of samples: {count1+count2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed data\n",
    "mix_data = pd.concat([GAN_data, smote_data, borderline_data, original_data], axis=0, ignore_index=True)         \n",
    "mix_data = mix_data.reset_index(drop=True)\n",
    "\n",
    "#data with one oversampling method and original data e.g.(smote+original)\n",
    "smote_data = pd.concat([smote_data, smote2_data, original_data], axis=0, ignore_index=True)\n",
    "smote_data = smote_data.reset_index(drop=True)\n",
    "borderline_data = pd.concat([borderline_data, borderline2_data, original_data], axis=0, ignore_index=True)\n",
    "borderline_data = borderline_data.reset_index(drop=True)\n",
    "GAN_data = pd.concat([GAN_data, GAN2_data, original_data], axis=0, ignore_index=True)\n",
    "GAN_data = GAN_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix, y_mix = mix_data.drop(columns=[\"target\", \"source\"]), mix_data[\"target\"]\n",
    "X_smote, y_smote = smote_data.drop(columns=[\"target\", \"source\"]), smote_data[\"target\"]\n",
    "X_GAN, y_GAN = GAN_data.drop(columns=[\"target\", \"source\"]), GAN_data[\"target\"]\n",
    "X_borderline, y_borderline = borderline_data.drop(columns=[\"target\", \"source\"]), borderline_data[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data[\"mix\"] = (X_mix, y_mix)\n",
    "data[\"smote\"] = (X_smote, y_smote)\n",
    "data[\"GAN\"] = (X_GAN, y_GAN)\n",
    "data[\"borderline\"] = (X_borderline, y_borderline)\n",
    "\n",
    "compare = {}\n",
    "compare[\"data\"] = mix_data\n",
    "compare[\"smote\"] = smote_data\n",
    "compare[\"GAN\"] = GAN_data\n",
    "compare[\"borderline\"] = borderline_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearMiss version1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "NM = NearMiss(version=1)\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "    \n",
    "    X_NM, y_NM = NM.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #concat resampled data\n",
    "    nearmiss_data = pd.concat([X_NM, y_NM], axis=1)\n",
    "    \n",
    "    NM_data_nosource = compare_df.drop(columns=[\"source\"])\n",
    "    nearmiss_data_nosource = nearmiss_data\n",
    "\n",
    "    for index, row in nearmiss_data_nosource.iterrows():\n",
    "        match = NM_data_nosource.eq(row).all(axis=1)  # Sprawdza, gdzie wiersze są identyczne\n",
    "        if match.any():  # Jeśli znaleziono dopasowanie\n",
    "            matched_index = match.idxmax()  # Pobiera pierwszy pasujący indeks\n",
    "            nearmiss_data.loc[index, \"source\"] = compare_df.loc[matched_index, \"source\"]\n",
    "            \n",
    "    nearmiss_data.to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_NM_data.csv\")\n",
    "    \n",
    "    print(f\"Data reduced for {name} data\")\n",
    "    print(nearmiss_data[\"target\"].value_counts())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
