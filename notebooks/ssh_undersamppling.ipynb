{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datacompy\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "# narzedzia\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    cross_val_predict,\n",
    "    learning_curve,\n",
    "    RepeatedStratifiedKFold,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from scipy import stats\n",
    "from joblib import dump, load\n",
    "\n",
    "# modele\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# methods\n",
    "from imblearn.under_sampling import ClusterCentroids, NearMiss\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from ctgan import CTGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #undersampling prepare data //mixed data (gan, brdsmote, smote)\\ncc_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\clustercentroids_data.csv\")\\nif_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\isolationforest_data.csv\")\\nnm_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\nearmiss_data.csv\")\\nmedian_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\median_data.csv\")\\nlof_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\localoutlierfactor_data.csv\") '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oversampling data\n",
    "original_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\original_data.csv\")    \n",
    "original_data = original_data.drop(columns=[\"Unnamed: 0\"])\n",
    "smote_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\smote_data.csv\")\n",
    "GAN_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\GAN_data.csv\")\n",
    "borderline_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\borderline_data.csv\")\n",
    "smote2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\smote3_data.csv\")\n",
    "GAN2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\GAN3_data.csv\")    \n",
    "borderline2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\borderline3_data.csv\")\n",
    "\n",
    "# test data\n",
    "X_test = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\test\\\\X_test.csv\")\n",
    "y_test = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\test\\\\y_test.csv\")\n",
    "\n",
    "\"\"\" #undersampling prepare data //mixed data (gan, brdsmote, smote)\n",
    "cc_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\clustercentroids_data.csv\")\n",
    "if_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\isolationforest_data.csv\")\n",
    "nm_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\nearmiss_data.csv\")\n",
    "median_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\median_data.csv\")\n",
    "lof_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\localoutlierfactor_data.csv\") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    151\n",
      "1     46\n",
      "Name: count, dtype: int64\n",
      "197\n",
      "Before undersampling: 105\n",
      "After number of samples: 302\n"
     ]
    }
   ],
   "source": [
    "print(original_data[\"target\"].value_counts())\n",
    "count1=original_data[\"target\"].value_counts().sum()\n",
    "print(count1)\n",
    "count2=abs((original_data['target']==0).sum() - (original_data['target']==1).sum())\n",
    "print(f\"Before undersampling: {count2}\")\n",
    "print(f\"After number of samples: {count1+count2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed data\n",
    "mix_data = pd.concat([GAN_data, smote_data, borderline_data, original_data], axis=0, ignore_index=True)         \n",
    "mix_data = mix_data.reset_index(drop=True)\n",
    "\n",
    "#data with one oversampling method and original data e.g.(smote+original)\n",
    "smote_data = pd.concat([smote_data, smote2_data, original_data], axis=0, ignore_index=True)\n",
    "smote_data = smote_data.reset_index(drop=True)\n",
    "borderline_data = pd.concat([borderline_data, borderline2_data, original_data], axis=0, ignore_index=True)\n",
    "borderline_data = borderline_data.reset_index(drop=True)\n",
    "GAN_data = pd.concat([GAN_data, GAN2_data, original_data], axis=0, ignore_index=True)\n",
    "GAN_data = GAN_data.reset_index(drop=True)\n",
    "\n",
    "sum_all_data = pd.concat([smote_data, GAN_data, borderline_data, mix_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix, y_mix = mix_data.drop(columns=[\"target\", \"source\"]), mix_data[\"target\"]\n",
    "X_smote, y_smote = smote_data.drop(columns=[\"target\", \"source\"]), smote_data[\"target\"]\n",
    "X_GAN, y_GAN = GAN_data.drop(columns=[\"target\", \"source\"]), GAN_data[\"target\"]\n",
    "X_borderline, y_borderline = borderline_data.drop(columns=[\"target\", \"source\"]), borderline_data[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data[\"mix\"] = (X_mix, y_mix)\n",
    "data[\"smote\"] = (X_smote, y_smote)\n",
    "data[\"GAN\"] = (X_GAN, y_GAN)\n",
    "data[\"borderline\"] = (X_borderline, y_borderline)\n",
    "\n",
    "compare = {}\n",
    "compare[\"mix\"] = mix_data\n",
    "compare[\"smote\"] = smote_data\n",
    "compare[\"GAN\"] = GAN_data\n",
    "compare[\"borderline\"] = borderline_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearMiss version1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "NM = NearMiss(version=1)\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "    \n",
    "    X_NM, y_NM = NM.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #concat resampled data\n",
    "    nearmiss_data = pd.concat([X_NM, y_NM], axis=1)\n",
    "    \n",
    "    NM_data_nosource = compare_df.drop(columns=[\"source\"])\n",
    "    nearmiss_data_nosource = nearmiss_data\n",
    "\n",
    "    for index, row in nearmiss_data_nosource.iterrows():\n",
    "        match = NM_data_nosource.eq(row).all(axis=1)  # Sprawdza, gdzie wiersze są identyczne\n",
    "        if match.any():  # Jeśli znaleziono dopasowanie\n",
    "            matched_index = match.idxmax()  # Pobiera pierwszy pasujący indeks\n",
    "            nearmiss_data.loc[index, \"source\"] = compare_df.loc[matched_index, \"source\"]\n",
    "            \n",
    "    nearmiss_data.to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_NM_data.csv\")\n",
    "    \n",
    "    print(f\"Data reduced for {name} data\")\n",
    "    print(nearmiss_data[\"target\"].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for mix data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for smote data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for GAN data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for borderline data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "KM = KMeans(n_clusters=(int)((count1+count2)/2))\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "    \n",
    "    X_majority = X_train[y_train == 1]\n",
    "    X_minority = X_train[y_train == 0]\n",
    "    \n",
    "    kmeans = KM.fit(X_majority)\n",
    "    \n",
    "    X_majority_reduced = pd.DataFrame(kmeans.cluster_centers_, columns=X_train.columns)\n",
    "    y_majority_reduced = pd.Series([0] * (int)((count1+count2)/2), name=\"target\")\n",
    "    \n",
    "    X_minority = X_minority.reset_index(drop=True)\n",
    "    y_minority = pd.Series([1] * len(X_minority), name=\"target\")\n",
    "    \n",
    "    X_final = pd.concat([X_majority_reduced, X_minority], axis=0).reset_index(drop=True)\n",
    "    y_final = pd.concat([y_majority_reduced, y_minority], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Concat resampled data\n",
    "    reduced_data = pd.concat([X_final, y_final], axis=1)\n",
    "    \n",
    "    # Compare data to copy source column\n",
    "    data_nosource = compare_df.drop(columns=[\"source\"])\n",
    "    reduced_data_nosource = reduced_data\n",
    "\n",
    "    # Iterate through the rows in reduced_data_nosource\n",
    "    for index, row in reduced_data_nosource.iterrows():\n",
    "        match = data_nosource.eq(row).all(axis=1)  # Check where rows are identical\n",
    "        if match.any():  # If a match is found\n",
    "            matched_index = match.idxmax()  # Get the first matching index\n",
    "            reduced_data.loc[index, \"source\"] = compare_df.loc[matched_index, \"source\"]\n",
    "    \n",
    "    reduced_data.to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_KM_data.csv\", index=False)\n",
    "    \n",
    "    print(f\"Data reduced for {name} data\")\n",
    "    print(reduced_data[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\_libs\\index.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m131\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mplot_scatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_CC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWard Linkage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Concat resampled data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m, in \u001b[0;36mplot_scatter\u001b[1;34m(X, color, alpha)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_scatter\u001b[39m(X, color, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, X[:, \u001b[38;5;241m1\u001b[39m], c\u001b[38;5;241m=\u001b[39mcolor, alpha\u001b[38;5;241m=\u001b[39malpha, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3660\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3660\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5737\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5735\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5736\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5737\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_scatter(X, color, alpha=0.5):\n",
    "    return plt.scatter(X[:, 0], X[:, 1], c=color, alpha=alpha, edgecolor=\"k\")\n",
    "\n",
    "AggC = AgglomerativeClustering(n_clusters=(int)((count1+count2)/2))\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "    \n",
    "    X_CC= AggC.fit_predict(X_train)    \n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plot_scatter(X_train, X_CC)\n",
    "    plt.title(\"Ward Linkage\")\n",
    "    \n",
    "    # Concat resampled data\n",
    "    reduced_data = pd.concat([X_CC, y_CC], axis=1)\n",
    "    \n",
    "    # Compare data to copy source column\n",
    "    data_nosource = compare_df.drop(columns=[\"source\"])\n",
    "    reduced_data_nosource = reduced_data\n",
    "\n",
    "    # Iterate through the rows in reduced_data_nosource\n",
    "    for index, row in reduced_data_nosource.iterrows():\n",
    "        match = data_nosource.eq(row).all(axis=1)  # Check where rows are identical\n",
    "        if match.any():  # If a match is found\n",
    "            matched_index = match.idxmax()  # Get the first matching index\n",
    "            reduced_data.loc[index, \"source\"] = compare_df.loc[matched_index, \"source\"]\n",
    "    \n",
    "    reduced_data.to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_CC_data.csv\", index=False)\n",
    "    \n",
    "    print(f\"Data reduced for {name} data\")\n",
    "    print(reduced_data[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for mix data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for smote data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for GAN data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for borderline data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "CC = ClusterCentroids(sampling_strategy=\"majority\", voting=\"auto\")\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "    \n",
    "    X_CC, y_CC = CC.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Concat resampled data\n",
    "    reduced_data = pd.concat([X_CC, y_CC], axis=1)\n",
    "    \n",
    "    # Compare data to copy source column\n",
    "    data_nosource = compare_df.drop(columns=[\"source\"])\n",
    "    reduced_data_nosource = reduced_data.drop(columns=[\"source\"], errors='ignore')\n",
    "\n",
    "    reduced_data[\"source\"] = None  # Initialize the source column with None\n",
    "\n",
    "    # Iterate through the rows in reduced_data_nosource\n",
    "    for index, row in reduced_data_nosource.iterrows():\n",
    "        match = data_nosource.eq(row).all(axis=1)  # Check where rows are identical\n",
    "        if match.any():  # If a match is found\n",
    "            matched_index = match.idxmax()  # Get the first matching index\n",
    "            reduced_data.loc[index, \"source\"] = compare_df.loc[matched_index, \"source\"]\n",
    "    \n",
    "    # Check for any rows that still have None in the source column\n",
    "    missing_source = reduced_data[reduced_data[\"source\"].isna()]\n",
    "    if not missing_source.empty:\n",
    "        reduced_data.loc[reduced_data[\"source\"].isna(), \"source\"] = \"centroid\"\n",
    "    \n",
    "    reduced_data.to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_CC_data.csv\", index=False)\n",
    "    \n",
    "    print(f\"Data reduced for {name} data\")\n",
    "    print(reduced_data[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = datacompy.Compare(\n",
    "        data_nosource,\n",
    "        reduced_data_nosource,\n",
    "        join_columns=data_nosource.columns.tolist(),  # List of columns to join on\n",
    "        abs_tol=1e-5,  # Absolute tolerance for comparing numeric values\n",
    "        rel_tol=1e-5,  # Relative tolerance for comparing numeric values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataComPy Comparison\n",
      "--------------------\n",
      "\n",
      "DataFrame Summary\n",
      "-----------------\n",
      "\n",
      "  DataFrame  Columns  Rows\n",
      "0       df1       13   919\n",
      "1       df2       14   302\n",
      "\n",
      "Column Summary\n",
      "--------------\n",
      "\n",
      "Number of columns in common: 13\n",
      "Number of columns in df1 but not in df2: 0\n",
      "Number of columns in df2 but not in df1: 1\n",
      "\n",
      "Row Summary\n",
      "-----------\n",
      "\n",
      "Matched on: user, is_private, is_failure, is_root, is_valid, not_valid_count, ip_failure, ip_success, no_failure, first, td, ts, target\n",
      "Any duplicates on match values: Yes\n",
      "Absolute Tolerance: 1e-05\n",
      "Relative Tolerance: 1e-05\n",
      "Number of rows in common: 223\n",
      "Number of rows in df1 but not in df2: 696\n",
      "Number of rows in df2 but not in df1: 79\n",
      "\n",
      "Number of rows with some compared columns unequal: 0\n",
      "Number of rows with all compared columns equal: 223\n",
      "\n",
      "Column Comparison\n",
      "-----------------\n",
      "\n",
      "Number of columns compared with some values unequal: 0\n",
      "Number of columns compared with all values equal: 13\n",
      "Total number of values which compare unequal: 0\n",
      "\n",
      "Sample Rows Only in df1 (First 10 Columns)\n",
      "------------------------------------------\n",
      "\n",
      "   user  is_private  is_failure  is_root  is_valid  not_valid_count  ip_failure  ip_success  no_failure  first\n",
      "0    23           1           1        0         0                0           6           1           8      0\n",
      "1    30           1           1        0         0                6          11           1           7      0\n",
      "2    32           1           1        0         0                6           6           0           7      0\n",
      "3    29           1           1        0         1                0           6           0          10      0\n",
      "4    17           1           1        0         0                0           4           1           7      0\n",
      "5    13           1           1        0         0               16          16           0          16      0\n",
      "6    29           1           1        0         0                1           8           1          10      0\n",
      "7    30           1           0        0         1                0           0           3           0      0\n",
      "8     9           1           1        0         0                8          39           0          39      0\n",
      "9    30           1           1        1         1                0           7           9          11      0\n",
      "\n",
      "Sample Rows Only in df2 (First 10 Columns)\n",
      "------------------------------------------\n",
      "\n",
      "   user  is_private  is_failure  is_root  is_valid  not_valid_count  ip_failure  ip_success  no_failure  first\n",
      "0    29           1           1        0         0                6          12           1           7      0\n",
      "1    20           1           1        0         0                3          10           1           7      0\n",
      "2    17           1           1        0         0                4          11           1           7      0\n",
      "3    28           1           1        0         0                6          10           0           8      0\n",
      "4     5           1           1        0         0               26          26           0          26      0\n",
      "5    17           1           1        0         0                0           4           0           9      0\n",
      "6    26           1           1        0         0                0           6           0          10      0\n",
      "7    31           1           1        0         1                0           4           0          16      0\n",
      "8    28           1           1        0         0                3           8           1           9      0\n",
      "9    39           0           1        0         1                0           2           0          11      0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(comparison.report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user', 'is_private', 'is_failure', 'is_root', 'is_valid', 'not_valid_count', 'ip_failure', 'ip_success', 'no_failure', 'first', 'td', 'ts', 'target', 'source']\n",
      "['user', 'is_private', 'is_failure', 'is_root', 'is_valid', 'not_valid_count', 'ip_failure', 'ip_success', 'no_failure', 'first', 'td', 'ts', 'target', 'source']\n"
     ]
    }
   ],
   "source": [
    "print(reduced_data.columns.to_list())\n",
    "print(borderline_data.columns.to_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
