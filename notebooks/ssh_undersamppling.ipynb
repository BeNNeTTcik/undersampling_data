{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datacompy\n",
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "# narzedzia\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    cross_val_predict,\n",
    "    learning_curve,\n",
    "    RepeatedStratifiedKFold,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from scipy import stats\n",
    "from joblib import dump, load\n",
    "\n",
    "# modele\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# methods\n",
    "from imblearn.under_sampling import ClusterCentroids, NearMiss\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from ctgan import CTGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSH_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\SSH_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #undersampling prepare data //mixed data (gan, brdsmote, smote)\\ncc_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\clustercentroids_data.csv\")\\nif_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\isolationforest_data.csv\")\\nnm_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\nearmiss_data.csv\")\\nmedian_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\median_data.csv\")\\nlof_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\localoutlierfactor_data.csv\") '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oversampling data\n",
    "original_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\original_data.csv\")    \n",
    "original_data = original_data.drop(columns=[\"Unnamed: 0\"])\n",
    "smote_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\smote_data.csv\")\n",
    "GAN_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\GAN_data.csv\")\n",
    "borderline_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\borderline_data.csv\")\n",
    "smote2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\smote3_data.csv\")\n",
    "GAN2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\GAN3_data.csv\")    \n",
    "borderline2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\borderline3_data.csv\")\n",
    "\n",
    "# test data\n",
    "X_test = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\test\\\\X_test.csv\")\n",
    "y_test = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\new\\\\test\\\\y_test.csv\")\n",
    "\n",
    "\"\"\" #undersampling prepare data //mixed data (gan, brdsmote, smote)\n",
    "cc_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\clustercentroids_data.csv\")\n",
    "if_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\isolationforest_data.csv\")\n",
    "nm_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\nearmiss_data.csv\")\n",
    "median_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\median_data.csv\")\n",
    "lof_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\localoutlierfactor_data.csv\") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataComPy Comparison\n",
      "--------------------\n",
      "\n",
      "DataFrame Summary\n",
      "-----------------\n",
      "\n",
      "       DataFrame  Columns  Rows\n",
      "0  original_data       14   197\n",
      "1         X_test       13    85\n",
      "\n",
      "Column Summary\n",
      "--------------\n",
      "\n",
      "Number of columns in common: 12\n",
      "Number of columns in original_data but not in X_test: 2\n",
      "Number of columns in X_test but not in original_data: 1\n",
      "\n",
      "Row Summary\n",
      "-----------\n",
      "\n",
      "Matched on: index\n",
      "Any duplicates on match values: No\n",
      "Absolute Tolerance: 0\n",
      "Relative Tolerance: 0\n",
      "Number of rows in common: 85\n",
      "Number of rows in original_data but not in X_test: 112\n",
      "Number of rows in X_test but not in original_data: 0\n",
      "\n",
      "Number of rows with some compared columns unequal: 85\n",
      "Number of rows with all compared columns equal: 0\n",
      "\n",
      "Column Comparison\n",
      "-----------------\n",
      "\n",
      "Number of columns compared with some values unequal: 12\n",
      "Number of columns compared with all values equal: 0\n",
      "Total number of values which compare unequal: 606\n",
      "\n",
      "Columns with Unequal Values or Types\n",
      "------------------------------------\n",
      "\n",
      "             Column original_data dtype X_test dtype  # Unequal       Max Diff  # Null Diff\n",
      "9             first               int64        int64         13       1.000000            0\n",
      "6        ip_failure               int64        int64         76      45.000000            0\n",
      "7        ip_success               int64        int64         70      33.000000            0\n",
      "2        is_failure               int64        int64         39       1.000000            0\n",
      "1        is_private               int64        int64          8       1.000000            0\n",
      "3           is_root               int64        int64         18       1.000000            0\n",
      "4          is_valid               int64        int64         31       1.000000            0\n",
      "8        no_failure               int64        int64         77      45.000000            0\n",
      "5   not_valid_count               int64        int64         39      24.000000            0\n",
      "10               td               int64        int64         81  322919.000000            0\n",
      "11               ts             float64      float64         85       2.482926            0\n",
      "0              user               int64        int64         69      32.000000            0\n",
      "\n",
      "Sample Rows with Unequal Values\n",
      "-------------------------------\n",
      "\n",
      "    user (original_data)  user (X_test)\n",
      "59                    29           40.0\n",
      "52                    30           19.0\n",
      "39                    15           37.0\n",
      "28                    30           19.0\n",
      "2                     24           40.0\n",
      "54                    33           30.0\n",
      "43                    18           22.0\n",
      "53                    30           40.0\n",
      "61                    40           30.0\n",
      "75                    37           30.0\n",
      "\n",
      "    is_private (original_data)  is_private (X_test)\n",
      "10                           0                  1.0\n",
      "47                           0                  1.0\n",
      "35                           1                  0.0\n",
      "75                           0                  1.0\n",
      "37                           0                  1.0\n",
      "3                            1                  0.0\n",
      "25                           0                  1.0\n",
      "38                           1                  0.0\n",
      "\n",
      "    is_failure (original_data)  is_failure (X_test)\n",
      "12                           1                  0.0\n",
      "63                           1                  0.0\n",
      "64                           1                  0.0\n",
      "10                           1                  0.0\n",
      "33                           0                  1.0\n",
      "76                           1                  0.0\n",
      "61                           1                  0.0\n",
      "15                           1                  0.0\n",
      "54                           1                  0.0\n",
      "40                           1                  0.0\n",
      "\n",
      "    is_root (original_data)  is_root (X_test)\n",
      "27                        0               1.0\n",
      "33                        0               1.0\n",
      "6                         1               0.0\n",
      "47                        1               0.0\n",
      "46                        0               1.0\n",
      "75                        1               0.0\n",
      "25                        1               0.0\n",
      "0                         0               1.0\n",
      "29                        0               1.0\n",
      "38                        0               1.0\n",
      "\n",
      "    is_valid (original_data)  is_valid (X_test)\n",
      "70                         1                0.0\n",
      "16                         1                0.0\n",
      "57                         0                1.0\n",
      "60                         1                0.0\n",
      "68                         0                1.0\n",
      "64                         0                1.0\n",
      "84                         0                1.0\n",
      "14                         1                0.0\n",
      "8                          1                0.0\n",
      "49                         1                0.0\n",
      "\n",
      "    not_valid_count (original_data)  not_valid_count (X_test)\n",
      "55                                2                       0.0\n",
      "41                                5                      18.0\n",
      "25                                0                       1.0\n",
      "62                               27                      14.0\n",
      "29                                3                       0.0\n",
      "31                                1                       5.0\n",
      "28                                0                       6.0\n",
      "6                                 0                      15.0\n",
      "40                                8                       0.0\n",
      "8                                 0                      10.0\n",
      "\n",
      "    ip_failure (original_data)  ip_failure (X_test)\n",
      "75                           7                  0.0\n",
      "33                           0                  1.0\n",
      "23                           4                  6.0\n",
      "3                            1                  9.0\n",
      "72                           0                  1.0\n",
      "32                           6                  2.0\n",
      "30                           0                  1.0\n",
      "29                          11                  7.0\n",
      "71                           1                  0.0\n",
      "84                          38                  0.0\n",
      "\n",
      "    ip_success (original_data)  ip_success (X_test)\n",
      "36                           2                  1.0\n",
      "58                           0                  1.0\n",
      "9                           22                  0.0\n",
      "38                           1                  0.0\n",
      "71                           1                 16.0\n",
      "7                            0                 14.0\n",
      "52                          21                 14.0\n",
      "44                           9                 14.0\n",
      "23                          32                  1.0\n",
      "2                            3                  1.0\n",
      "\n",
      "    no_failure (original_data)  no_failure (X_test)\n",
      "70                           3                 34.0\n",
      "50                           0                 24.0\n",
      "59                          20                 13.0\n",
      "31                          32                 36.0\n",
      "54                           1                  0.0\n",
      "9                           20                  2.0\n",
      "53                           2                  1.0\n",
      "64                           3                  0.0\n",
      "12                           2                  0.0\n",
      "79                           0                 13.0\n",
      "\n",
      "    first (original_data)  first (X_test)\n",
      "59                      0             1.0\n",
      "3                       1             0.0\n",
      "15                      0             1.0\n",
      "80                      1             0.0\n",
      "17                      1             0.0\n",
      "46                      1             0.0\n",
      "48                      1             0.0\n",
      "10                      1             0.0\n",
      "45                      0             1.0\n",
      "30                      0             1.0\n",
      "\n",
      "    td (original_data)  td (X_test)\n",
      "45                 311          0.0\n",
      "25                 116          9.0\n",
      "29                  10          6.0\n",
      "41                  14          6.0\n",
      "22                   1         71.0\n",
      "17                   0        142.0\n",
      "11                 224          4.0\n",
      "67                  11        131.0\n",
      "49                  61          3.0\n",
      "53                3507         13.0\n",
      "\n",
      "    ts (original_data)  ts (X_test)\n",
      "3             0.530034     0.538299\n",
      "48            0.530042    -1.885633\n",
      "12            0.530035     0.538301\n",
      "69            0.538241     0.530041\n",
      "42            0.530041     0.530036\n",
      "33            0.538242     0.511121\n",
      "11            0.539569     0.539521\n",
      "58           -1.952881     0.530046\n",
      "41            0.511620    -1.885640\n",
      "63            0.522730     0.540242\n",
      "\n",
      "Sample Rows Only in original_data (First 10 Columns)\n",
      "----------------------------------------------------\n",
      "\n",
      "     user  is_private  is_failure  is_root  is_valid  not_valid_count  ip_failure  ip_success  no_failure  first\n",
      "87     18           1           1        0         0                4          12           2           5      0\n",
      "194    32           1           1        0         0                7           7           0           7      0\n",
      "168    40           1           0        0         1                0           0           1           0      0\n",
      "104    10           1           1        0         0               13          13           0          13      0\n",
      "103    18           1           1        1         1                0           5           2           7      0\n",
      "122    30           1           1        0         1                0           4           9           7      0\n",
      "102    37           0           1        1         1                0           4           0           6      0\n",
      "153    24           1           1        0         1                0           2           0           3      0\n",
      "136    19           1           1        0         0                3           3          22           4      0\n",
      "149    30           1           0        0         1                0           0           1           0      1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare = datacompy.Compare(\n",
    "    original_data, X_test, on_index=True, abs_tol=0, rel_tol=0, df1_name=\"original_data\", df2_name=\"X_test\"\n",
    ")\n",
    "print(compare.report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    151\n",
      "1     46\n",
      "Name: count, dtype: int64\n",
      "197\n",
      "Before undersampling: 105\n",
      "After number of samples: 302\n"
     ]
    }
   ],
   "source": [
    "print(original_data[\"target\"].value_counts())\n",
    "count1=original_data[\"target\"].value_counts().sum()\n",
    "print(count1)\n",
    "count2=abs((original_data['target']==0).sum() - (original_data['target']==1).sum())\n",
    "print(f\"Before undersampling: {count2}\")\n",
    "print(f\"After number of samples: {count1+count2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form original data remove X_test data\n",
    "original_data = original_data[~original_data.isin(X_test)].dropna()\n",
    "original_data = original_data.reset_index(drop=True)\n",
    "\n",
    "#mixed data\n",
    "mix_data = pd.concat([GAN_data, smote_data, borderline_data, original_data], axis=0, ignore_index=True)         \n",
    "mix_data = mix_data.reset_index(drop=True)\n",
    "\n",
    "#data with one oversampling method and original data e.g.(smote+original)\n",
    "smote_data = pd.concat([smote_data, smote2_data, original_data], axis=0, ignore_index=True)\n",
    "smote_data = smote_data.reset_index(drop=True)\n",
    "borderline_data = pd.concat([borderline_data, borderline2_data, original_data], axis=0, ignore_index=True)\n",
    "borderline_data = borderline_data.reset_index(drop=True)\n",
    "GAN_data = pd.concat([GAN_data, GAN2_data, original_data], axis=0, ignore_index=True)\n",
    "GAN_data = GAN_data.reset_index(drop=True)\n",
    "\n",
    "sum_all_data = pd.concat([smote_data, GAN_data, borderline_data, mix_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix, y_mix = mix_data.drop(columns=[\"target\", \"source\"]), mix_data[\"target\"]\n",
    "X_smote, y_smote = smote_data.drop(columns=[\"target\", \"source\"]), smote_data[\"target\"]\n",
    "X_GAN, y_GAN = GAN_data.drop(columns=[\"target\", \"source\"]), GAN_data[\"target\"]\n",
    "X_borderline, y_borderline = borderline_data.drop(columns=[\"target\", \"source\"]), borderline_data[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data[\"mix\"] = (X_mix, y_mix)\n",
    "data[\"smote\"] = (X_smote, y_smote)\n",
    "data[\"GAN\"] = (X_GAN, y_GAN)\n",
    "data[\"borderline\"] = (X_borderline, y_borderline)\n",
    "\n",
    "compare = {}\n",
    "compare[\"mix\"] = mix_data\n",
    "compare[\"smote\"] = smote_data\n",
    "compare[\"GAN\"] = GAN_data\n",
    "compare[\"borderline\"] = borderline_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearMiss version1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "NM = NearMiss(version=1)\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "    \n",
    "    X_NM, y_NM = NM.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #concat resampled data\n",
    "    nearmiss_data = pd.concat([X_NM, y_NM], axis=1)\n",
    "    \n",
    "    NM_data_nosource = compare_df.drop(columns=[\"source\"])\n",
    "    nearmiss_data_nosource = nearmiss_data\n",
    "\n",
    "    for index, row in nearmiss_data_nosource.iterrows():\n",
    "        match = NM_data_nosource.eq(row).all(axis=1)  # Sprawdza, gdzie wiersze są identyczne\n",
    "        if match.any():  # Jeśli znaleziono dopasowanie\n",
    "            matched_index = match.idxmax()  # Pobiera pierwszy pasujący indeks\n",
    "            nearmiss_data.loc[index, \"source\"] = compare_df.loc[matched_index, \"source\"]\n",
    "            \n",
    "    nearmiss_data.to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_NM_data.csv\")\n",
    "    \n",
    "    print(f\"Data reduced for {name} data\")\n",
    "    print(nearmiss_data[\"target\"].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for mix data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for smote data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for GAN data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for borderline data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "KM = KMeans(n_clusters=(int)((count1+count2)/2))\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "    \n",
    "    X_majority = X_train[y_train == 1]\n",
    "    X_minority = X_train[y_train == 0]\n",
    "    \n",
    "    kmeans = KM.fit(X_majority)\n",
    "    \n",
    "    X_majority_reduced = pd.DataFrame(kmeans.cluster_centers_, columns=X_train.columns)\n",
    "    y_majority_reduced = pd.Series([0] * (int)((count1+count2)/2), name=\"target\")\n",
    "    \n",
    "    X_minority = X_minority.reset_index(drop=True)\n",
    "    y_minority = pd.Series([1] * len(X_minority), name=\"target\")\n",
    "    \n",
    "    X_final = pd.concat([X_majority_reduced, X_minority], axis=0).reset_index(drop=True)\n",
    "    y_final = pd.concat([y_majority_reduced, y_minority], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Concat resampled data\n",
    "    reduced_data = pd.concat([X_final, y_final], axis=1)\n",
    "    \n",
    "    reduced_data[\"source\"] = None  # Initialize the source column with None\n",
    "    \n",
    "    # Compare data to copy source column\n",
    "    data_nosource = compare_df.drop(columns=[\"source\"])\n",
    "    reduced_data_nosource = reduced_data\n",
    "\n",
    "    # Iterate through the rows in reduced_data_nosource\n",
    "    for index, row in reduced_data_nosource.iterrows():\n",
    "        match = data_nosource.eq(row).all(axis=1)  # Check where rows are identical\n",
    "        if match.any():  # If a match is found\n",
    "            matched_index = match.idxmax()  # Get the first matching index\n",
    "            reduced_data.loc[index, \"source\"] = compare_df.loc[matched_index, \"source\"]\n",
    "            \n",
    "    # Check for any rows that still have None in the source column\n",
    "    missing_source = reduced_data[reduced_data[\"source\"].isna()]\n",
    "    if not missing_source.empty:\n",
    "        reduced_data.loc[reduced_data[\"source\"].isna(), \"source\"] = \"centroid\"       \n",
    "    \n",
    "    reduced_data.to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_KM_data.csv\", index=False)\n",
    "    \n",
    "    print(f\"Data reduced for {name} data\")\n",
    "    print(reduced_data[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for mix data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for smote data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for GAN data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for borderline data\n",
      "target\n",
      "0    151\n",
      "1    151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "CC = ClusterCentroids(sampling_strategy=\"majority\", voting=\"auto\")\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "    \n",
    "    X_CC, y_CC = CC.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Concat resampled data\n",
    "    reduced_data = pd.concat([X_CC, y_CC], axis=1)\n",
    "    \n",
    "    # Compare data to copy source column\n",
    "    data_nosource = compare_df.drop(columns=[\"source\"])\n",
    "    reduced_data_nosource = reduced_data.drop(columns=[\"source\"], errors='ignore')\n",
    "\n",
    "    reduced_data[\"source\"] = None  # Initialize the source column with None\n",
    "\n",
    "    # Iterate through the rows in reduced_data_nosource\n",
    "    for index, row in reduced_data_nosource.iterrows():\n",
    "        match = data_nosource.eq(row).all(axis=1)  # Check where rows are identical\n",
    "        if match.any():  # If a match is found\n",
    "            matched_index = match.idxmax()  # Get the first matching index\n",
    "            reduced_data.loc[index, \"source\"] = compare_df.loc[matched_index, \"source\"]\n",
    "    \n",
    "    # Check for any rows that still have None in the source column\n",
    "    missing_source = reduced_data[reduced_data[\"source\"].isna()]\n",
    "    if not missing_source.empty:\n",
    "        reduced_data.loc[reduced_data[\"source\"].isna(), \"source\"] = \"centroid\"\n",
    "    \n",
    "    reduced_data.to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_CC_data.csv\", index=False)\n",
    "    \n",
    "    print(f\"Data reduced for {name} data\")\n",
    "    print(reduced_data[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "models[\"LR\"]        = LogisticRegression()\n",
    "models[\"LR_mix\"]    = LogisticRegression()\n",
    "models[\"LR_smote\"]  = LogisticRegression()\n",
    "models[\"LR_GAN\"]    = LogisticRegression()\n",
    "models[\"LR_borderline\"] = LogisticRegression()\n",
    "\n",
    "models[\"DT\"]        = DecisionTreeClassifier()\n",
    "models[\"DT_mix\"]    = DecisionTreeClassifier()\n",
    "models[\"DT_smote\"]  = DecisionTreeClassifier()\n",
    "models[\"DT_GAN\"]    = DecisionTreeClassifier()\n",
    "models[\"DT_borderline\"] = DecisionTreeClassifier()\n",
    "\n",
    "models[\"RF\"]        = RandomForestClassifier()\n",
    "models[\"RF_mix\"]    = RandomForestClassifier()\n",
    "models[\"RF_smote\"]  = RandomForestClassifier()\n",
    "models[\"RF_GAN\"]    = RandomForestClassifier()\n",
    "models[\"RF_borderline\"] = RandomForestClassifier()\n",
    "\n",
    "models[\"XGB\"]       = XGBClassifier()\n",
    "models[\"XGB_mix\"]   = XGBClassifier()\n",
    "models[\"XGB_smote\"] = XGBClassifier()\n",
    "models[\"XGB_GAN\"]   = XGBClassifier()\n",
    "models[\"XGB_borderline\"] = XGBClassifier()\n",
    "\n",
    "models[\"XGBRF\"]     = XGBRFClassifier()\n",
    "models[\"XGBRF_mix\"] = XGBRFClassifier()\n",
    "models[\"XGBRF_smote\"] = XGBRFClassifier()\n",
    "models[\"XGBRF_GAN\"] = XGBRFClassifier()\n",
    "models[\"XGBRF_borderline\"] = XGBRFClassifier()\n",
    "\n",
    "\n",
    "trainig_data = {}\n",
    "trainig_data[\"LR\"]=\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
