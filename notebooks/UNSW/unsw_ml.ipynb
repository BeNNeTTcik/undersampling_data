{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datacompy\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "# narzedzia\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    cross_val_predict,\n",
    "    learning_curve,\n",
    "    RepeatedStratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score, accuracy_score, pairwise_distances, make_scorer, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, f_oneway, friedmanchisquare, wilcoxon\n",
    "from scipy.spatial import distance\n",
    "from joblib import dump, load\n",
    "\n",
    "# modele\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# methods\n",
    "from imblearn.under_sampling import ClusterCentroids, NearMiss\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, HDBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor, KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.spatial.distance import euclidean\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from ctgan import CTGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72ecb3",
   "metadata": {},
   "source": [
    "### Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original df\n",
    "original = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\encoded_normalized\\\\original_data_normalized.csv\")\n",
    "\n",
    "# KMeans + centeroid\n",
    "borderline_KM_cent = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\borderline_KM_centroids.csv\")\n",
    "smote_KM_cent = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\smote_KM_centroids.csv\")\n",
    "mix_KM_cent = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\mix_KM_centroids.csv\")\n",
    "GAN_KM_cent = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\GAN_KM_centroids.csv\")\n",
    "\n",
    "# KMeans + the nearesrt neighbor\n",
    "borderline_KM_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\borderline_KM_nn.csv\")\n",
    "smote_KM_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\smote_KM_nn.csv\")\n",
    "mix_KM_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\mix_KM_nn.csv\")\n",
    "GAN_KM_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\GAN_KM_nn.csv\")\n",
    "\n",
    "# KMeans + cosine similarity\n",
    "borderline_KM_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\borderline_KM_cos.csv\")\n",
    "smote_KM_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\smote_KM_cos.csv\")\n",
    "mix_KM_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\mix_KM_cos.csv\")\n",
    "GAN_KM_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\GAN_KM_cos.csv\")\n",
    "\n",
    "# KMeans + cosine similarity + Mahalanobis distance\n",
    "borderline_KM_cos_maha = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\borderline_KM_cos_mal.csv\")\n",
    "smote_KM_cos_maha = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\smote_KM_cos_mal.csv\")\n",
    "mix_KM_cos_maha = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\mix_KM_cos_mal.csv\")\n",
    "GAN_KM_cos_maha = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\GAN_KM_cos_mal.csv\")\n",
    "\n",
    "# HDBSCAN + the nearesrt neighbor\n",
    "borderline_HDBSCAN_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\borderline_HDBSCAN_NN.csv\")\n",
    "smote_HDBSCAN_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\smote_HDBSCAN_NN.csv\")\n",
    "mix_HDBSCAN_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\mix_HDBSCAN_NN.csv\")\n",
    "GAN_HDBSCAN_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\GAN_HDBSCAN_NN.csv\")\n",
    "\n",
    "# HDBSCAN + cosine similarity\n",
    "borderline_HDBSCAN_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\borderline_HDBSCAN_cos.csv\")\n",
    "smote_HDBSCAN_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\smote_HDBSCAN_cos.csv\")\n",
    "mix_HDBSCAN_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\mix_HDBSCAN_cos.csv\")\n",
    "GAN_HDBSCAN_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\GAN_HDBSCAN_cos.csv\")\n",
    "\n",
    "# Kmeans(number of samples calculated by HDBSCAN) + the nearesrt neighbor\n",
    "borderline_KM_HDBSCAN_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\borderline_kmeans&hdbscan_nn.csv\")\n",
    "smote_KM_HDBSCAN_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\smote_kmeans&hdbscan_nn.csv\")\n",
    "mix_KM_HDBSCAN_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\mix_kmeans&hdbscan_nn.csv\")\n",
    "GAN_KM_HDBSCAN_nn = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\GAN_kmeans&hdbscan_nn.csv\")\n",
    "\n",
    "# Kmeans(number of samples calculated by HDBSCAN) + cosine similarity\n",
    "borderline_KM_HDBSCAN_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\borderline_kmeans&hdbscan_cos.csv\")\n",
    "smote_KM_HDBSCAN_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\smote_kmeans&hdbscan_cos.csv\")\n",
    "mix_KM_HDBSCAN_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\mix_kmeans&hdbscan_cos.csv\")\n",
    "GAN_KM_HDBSCAN_cos = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\GAN_kmeans&hdbscan_cos.csv\")  \n",
    "\n",
    "# KMeans(number of samples calculated by HDBSCAN) + cosine similarity + Mahalanobis distance\n",
    "borderline_KM_HDBSCAN_cos_maha = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\borderline_kmeans&hdbscan_cos&mal.csv\")\n",
    "smote_KM_HDBSCAN_cos_maha = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\smote_kmeans&hdbscan_cos&mal.csv\")\n",
    "mix_KM_HDBSCAN_cos_maha = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\mix_kmeans&hdbscan_cos&mal.csv\")\n",
    "GAN_KM_HDBSCAN_cos_maha = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\reduced\\\\GAN_kmeans&hdbscan_cos&mal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# Data for grid search\n",
    "\"\"\" data[\"original\"] = (original.drop(columns=[\"target\",\"source\"]), original[\"target\"])\n",
    "data[\"KM_C\"] = (borderline_KM_cent.drop(columns=[\"target\",\"source\"]), borderline_KM_cent[\"target\"])\n",
    "data[\"KM_NN\"] = (borderline_KM_nn.drop(columns=[\"target\",\"source\"]), borderline_KM_nn[\"target\"])\n",
    "data[\"KM_COS\"] = (borderline_KM_cos.drop(columns=[\"target\",\"source\"]), borderline_KM_cos[\"target\"])\n",
    "data[\"KM_COS_MAHA\"] = (borderline_KM_cos_maha.drop(columns=[\"target\",\"source\"]), borderline_KM_cos_maha[\"target\"])\n",
    "data[\"HDBSCAN_NN\"] = (borderline_HDBSCAN_nn.drop(columns=[\"target\",\"source\"]), borderline_HDBSCAN_nn[\"target\"])\n",
    "data[\"HDBSCAN_COS\"] = (borderline_HDBSCAN_cos.drop(columns=[\"target\",\"source\"]), borderline_HDBSCAN_cos[\"target\"])\n",
    "data[\"KM_SCAN_NN\"] = (borderline_KM_HDBSCAN_nn.drop(columns=[\"target\",\"source\"]), borderline_KM_HDBSCAN_nn[\"target\"])\n",
    "data[\"KM_SCAN_COS\"] = (borderline_KM_HDBSCAN_cos.drop(columns=[\"target\",\"source\"]), borderline_KM_HDBSCAN_cos[\"target\"])\n",
    "data[\"KM_SCAN_COS_MAHA\"] = (borderline_KM_HDBSCAN_cos_maha.drop(columns=[\"target\",\"source\"]), borderline_KM_HDBSCAN_cos_maha[\"target\"]) \"\"\"\n",
    "\n",
    "# Data for models\n",
    "data[\"DT\"] = (original.drop(columns=[\"target\",\"source\"]), original[\"target\"])\n",
    "data[\"DT_KM_C\"] = (borderline_KM_cent.drop(columns=[\"target\",\"source\"]), borderline_KM_cent[\"target\"])\n",
    "data[\"DT_KM_NN\"] = (borderline_KM_nn.drop(columns=[\"target\",\"source\"]), borderline_KM_nn[\"target\"])\n",
    "data[\"DT_KM_COS\"] = (borderline_KM_cos.drop(columns=[\"target\",\"source\"]), borderline_KM_cos[\"target\"])\n",
    "data[\"DT_KM_COS_MAHA\"] = (borderline_KM_cos_maha.drop(columns=[\"target\",\"source\"]), borderline_KM_cos_maha[\"target\"])\n",
    "data[\"DT_HDBSCAN_NN\"] = (borderline_HDBSCAN_nn.drop(columns=[\"target\",\"source\"]), borderline_HDBSCAN_nn[\"target\"])\n",
    "data[\"DT_HDBSCAN_COS\"] = (borderline_HDBSCAN_cos.drop(columns=[\"target\",\"source\"]), borderline_HDBSCAN_cos[\"target\"])\n",
    "data[\"DT_KM_SCAN_NN\"] = (borderline_KM_HDBSCAN_nn.drop(columns=[\"target\",\"source\"]), borderline_KM_HDBSCAN_nn[\"target\"])\n",
    "data[\"DT_KM_SCAN_COS\"] = (borderline_KM_HDBSCAN_cos.drop(columns=[\"target\",\"source\"]), borderline_KM_HDBSCAN_cos[\"target\"])\n",
    "data[\"DT_KM_SCAN_COS_MAHA\"] = (borderline_KM_HDBSCAN_cos_maha.drop(columns=[\"target\",\"source\"]), borderline_KM_HDBSCAN_cos_maha[\"target\"])\n",
    "\n",
    "data[\"RF\"] = (original.drop(columns=[\"target\",\"source\"]), original[\"target\"])\n",
    "data[\"RF_KM_C\"] = (smote_KM_cent.drop(columns=[\"target\",\"source\"]), smote_KM_cent[\"target\"])\n",
    "data[\"RF_KM_NN\"] = (smote_KM_nn.drop(columns=[\"target\",\"source\"]), smote_KM_nn[\"target\"])\n",
    "data[\"RF_KM_COS\"] = (smote_KM_cos.drop(columns=[\"target\",\"source\"]), smote_KM_cos[\"target\"])\n",
    "data[\"RF_KM_COS_MAHA\"] = (smote_KM_cos_maha.drop(columns=[\"target\",\"source\"]), smote_KM_cos_maha[\"target\"])\n",
    "data[\"RF_HDBSCAN_NN\"] = (smote_HDBSCAN_nn.drop(columns=[\"target\",\"source\"]), smote_HDBSCAN_nn[\"target\"])\n",
    "data[\"RF_HDBSCAN_COS\"] = (smote_HDBSCAN_cos.drop(columns=[\"target\",\"source\"]), smote_HDBSCAN_cos[\"target\"])\n",
    "data[\"RF_KM_SCAN_NN\"] = (smote_KM_HDBSCAN_nn.drop(columns=[\"target\",\"source\"]), smote_KM_HDBSCAN_nn[\"target\"])\n",
    "data[\"RF_KM_SCAN_COS\"] = (smote_KM_HDBSCAN_cos.drop(columns=[\"target\",\"source\"]), smote_KM_HDBSCAN_cos[\"target\"])\n",
    "data[\"RF_KM_SCAN_COS_MAHA\"] = (smote_KM_HDBSCAN_cos_maha.drop(columns=[\"target\",\"source\"]), smote_KM_HDBSCAN_cos_maha[\"target\"])\n",
    "\n",
    "data[\"XGB\"] = (original.drop(columns=[\"target\",\"source\"]), original[\"target\"])\n",
    "data[\"XGB_KM_C\"] = (mix_KM_cent.drop(columns=[\"target\",\"source\"]), mix_KM_cent[\"target\"])\n",
    "data[\"XGB_KM_NN\"] = (mix_KM_nn.drop(columns=[\"target\",\"source\"]), mix_KM_nn[\"target\"])\n",
    "data[\"XGB_KM_COS\"] = (mix_KM_cos.drop(columns=[\"target\",\"source\"]), mix_KM_cos[\"target\"])\n",
    "data[\"XGB_KM_COS_MAHA\"] = (mix_KM_cos_maha.drop(columns=[\"target\",\"source\"]), mix_KM_cos_maha[\"target\"])\n",
    "data[\"XGB_HDBSCAN_NN\"] = (mix_HDBSCAN_nn.drop(columns=[\"target\",\"source\"]), mix_HDBSCAN_nn[\"target\"])\n",
    "data[\"XGB_HDBSCAN_COS\"] = (mix_HDBSCAN_cos.drop(columns=[\"target\",\"source\"]), mix_HDBSCAN_cos[\"target\"])\n",
    "data[\"XGB_KM_SCAN_NN\"] = (mix_KM_HDBSCAN_nn.drop(columns=[\"target\",\"source\"]), mix_KM_HDBSCAN_nn[\"target\"])\n",
    "data[\"XGB_KM_SCAN_COS\"] = (mix_KM_HDBSCAN_cos.drop(columns=[\"target\",\"source\"]), mix_KM_HDBSCAN_cos[\"target\"])\n",
    "data[\"XGB_KM_SCAN_COS_MAHA\"] = (mix_KM_HDBSCAN_cos_maha.drop(columns=[\"target\",\"source\"]), mix_KM_HDBSCAN_cos_maha[\"target\"])\n",
    "\n",
    "data[\"XGBRF\"] = (original.drop(columns=[\"target\",\"source\"]), original[\"target\"])\n",
    "data[\"XGBRF_KM_C\"] = (GAN_KM_cent.drop(columns=[\"target\",\"source\"]), GAN_KM_cent[\"target\"])\n",
    "data[\"XGBRF_KM_NN\"] = (GAN_KM_nn.drop(columns=[\"target\",\"source\"]), GAN_KM_nn[\"target\"])\n",
    "data[\"XGBRF_KM_COS\"] = (GAN_KM_cos.drop(columns=[\"target\",\"source\"]), GAN_KM_cos[\"target\"])\n",
    "data[\"XGBRF_KM_COS_MAHA\"] = (GAN_KM_cos_maha.drop(columns=[\"target\",\"source\"]), GAN_KM_cos_maha[\"target\"])\n",
    "data[\"XGBRF_HDBSCAN_NN\"] = (GAN_HDBSCAN_nn.drop(columns=[\"target\",\"source\"]), GAN_HDBSCAN_nn[\"target\"])\n",
    "data[\"XGBRF_HDBSCAN_COS\"] = (GAN_HDBSCAN_cos.drop(columns=[\"target\",\"source\"]), GAN_HDBSCAN_cos[\"target\"])\n",
    "data[\"XGBRF_KM_SCAN_NN\"] = (GAN_KM_HDBSCAN_nn.drop(columns=[\"target\",\"source\"]), GAN_KM_HDBSCAN_nn[\"target\"])\n",
    "data[\"XGBRF_KM_SCAN_COS\"] = (GAN_KM_HDBSCAN_cos.drop(columns=[\"target\",\"source\"]), GAN_KM_HDBSCAN_cos[\"target\"])\n",
    "data[\"XGBRF_KM_SCAN_COS_MAHA\"] = (GAN_KM_HDBSCAN_cos_maha.drop(columns=[\"target\",\"source\"]), GAN_KM_HDBSCAN_cos_maha[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b64d206",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b345860",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ = {\n",
    "    \"DT\": {\n",
    "        'max_depth': [4, 8],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'random_state': [0]\n",
    "    },\n",
    "    \"RF\": {\n",
    "        'n_estimators': [40, 80],\n",
    "        'max_depth': [8, 12],\n",
    "        'min_samples_leaf': [1],\n",
    "        'random_state': [0]\n",
    "    },\n",
    "    \"XGB\": {\n",
    "        'max_depth': [8, 12],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'subsample': [0.7, 1]\n",
    "    },\n",
    "    \"XGBRF\": {\n",
    "        'n_estimators': [40, 80],\n",
    "        'max_depth': [8],\n",
    "        'subsample': [0.7, 1],\n",
    "        'random_state': [0]\n",
    "    }\n",
    "}\n",
    "\n",
    "models_ = {\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"XGB\": XGBClassifier(verbosity=0, use_label_encoder=False),\n",
    "    \"XGBRF\": XGBClassifier(booster='gbtree', grow_policy='depthwise', importance_type='gain', tree_method='auto', verbosity=0, use_label_encoder=False)\n",
    "}\n",
    "\n",
    "results_ = {}\n",
    "\n",
    "n_iter = 30\n",
    "\n",
    "scoring_metrics = {\n",
    "    'precision': 'precision',\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1-score': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "\n",
    "for name, (X, y) in data.items():\n",
    "    print(f\"\\nüü¶ Dataset: {name}\")\n",
    "    results_[name] = {}\n",
    "\n",
    "    for model_name in models_.keys():\n",
    "        print(f\" üîç Model: {model_name}\")\n",
    "        model = models_[model_name]\n",
    "        param_dist = params_[model_name]\n",
    "\n",
    "        results_[name][model_name] = {}\n",
    "\n",
    "        for metric_name, metric in scoring_metrics.items():\n",
    "            print(f\"    üìä Metric: {metric_name}\")\n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=model,\n",
    "                param_distributions=param_dist,\n",
    "                n_iter=20,\n",
    "                scoring=metric,\n",
    "                cv=10,\n",
    "                n_jobs=-1,\n",
    "                verbose=0,\n",
    "                random_state=42,\n",
    "                return_train_score=False\n",
    "            )\n",
    "\n",
    "            search.fit(X, y)\n",
    "\n",
    "            results_[name][model_name][metric_name] = {\n",
    "                'best_score': search.best_score_,\n",
    "                'mean_test_score': np.mean(search.cv_results_['mean_test_score']),\n",
    "                'best_params': search.best_params_\n",
    "            }\n",
    "\n",
    "            print(f\"      ‚úÖ Best score: {search.best_score_:.4f}\")\n",
    "            print(f\"      üìà Mean score: {np.mean(search.cv_results_['mean_test_score']):.4f}\")\n",
    "            \n",
    "            \n",
    "summary = []\n",
    "\n",
    "for dataset_name in results_:\n",
    "    for model_name in results_[dataset_name]:\n",
    "        for metric_name in results_[dataset_name][model_name]:\n",
    "            entry = results_[dataset_name][model_name][metric_name]\n",
    "            summary.append({\n",
    "                \"Dataset\": dataset_name,\n",
    "                \"Model\": model_name,\n",
    "                \"Metric\": metric_name,\n",
    "                \"Best Score\": entry[\"best_score\"],\n",
    "                \"Mean Score\": entry[\"mean_test_score\"],\n",
    "                \"Best Params\": entry[\"best_params\"]\n",
    "            })\n",
    "\n",
    "df_results = pd.DataFrame(summary)\n",
    "df_results.to_csv(\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\grid_search\\\\results_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f2eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)\n",
    "results_cross_mean_under=[]\n",
    "results_cross_std_under=[]\n",
    "goal = ['accuracy', 'precision','f1','recall']\n",
    "path_files = [\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\accuracy_metrics.txt\",\n",
    "              \"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\precision_metrics.txt\", \n",
    "              \"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\f1_metrics.txt\", \n",
    "              \"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\recall_metrics.txt\"]\n",
    "\n",
    "excel_file_cross = \"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\cross.xlsx\"\n",
    "excel_file_cross2 = \"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\cross_std.xlsx\"\n",
    "name_sheet1 = \"Arkusz1\"\n",
    "\n",
    "raw_scores = {metric: {} for metric in goal}\n",
    "\n",
    "# Loop 10x10 cross validation for all models and all datasets\n",
    "for metrix1, path_file in zip(goal, path_files):\n",
    "    for model_key, (X_train, y_train) in data.items():\n",
    "        model = models[model_key]\n",
    "        \n",
    "        # Cross validation\n",
    "        cross_val_results = cross_val_score(model, X_train, y_train, cv=cv, scoring=metrix1, n_jobs=1)\n",
    "        print(f\"Learn: {metrix1} and model {model_key}\")\n",
    "        \n",
    "        raw_scores[metrix1][model_key] = cross_val_results\n",
    "        \n",
    "        # Save results to file\n",
    "        with open(path_file, \"a+\") as f:\n",
    "            # Zapis wynik√≥w do pliku\n",
    "            print(f'{model_key} Cross-Validation Results {metrix1}:\\n {cross_val_results}', file=f)\n",
    "            print(f'Mean {metrix1}: {cross_val_results.mean()}', file=f)\n",
    "            print(f'Dev: {cross_val_results.std()}', file=f)\n",
    "            print(\"\\n\", file=f)\n",
    "        \n",
    "        # Collect results for DataFrame\n",
    "        results_cross_mean_under.append({\n",
    "        \"Model\": model_key,\n",
    "        \"Metric\": metrix1,\n",
    "        \"Result\": cross_val_results.mean()})\n",
    "        results_cross_std_under.append({\n",
    "        \"Model\": model_key,\n",
    "        \"Metric\": metrix1,\n",
    "        \"Std\": cross_val_results.std()})\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        with open(f\"D:\\\\ml\\\\undersampling_data\\\\models\\\\unsw\\\\{model_key}_{metrix1}_model.pkl\", \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "    \n",
    "    # Save raw scores to CSV        \n",
    "    df_raw = pd.DataFrame(raw_scores[metrix1])\n",
    "    df_raw.to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\raw_scores_{metrix1}.csv\", index=False)  \n",
    "          \n",
    "# Create DataFrames and save to Excel           \n",
    "df_results_cross_under_mean = pd.DataFrame(results_cross_mean_under)\n",
    "df_results_cross_under_std = pd.DataFrame(results_cross_std_under)\n",
    "\n",
    "df_save_under_mean = df_results_cross_under_mean.pivot(index=\"Metric\", columns=\"Model\", values=\"Result\")\n",
    "df_save_under_std = df_results_cross_under_std.pivot(index=\"Metric\", columns=\"Model\", values=\"Std\")\n",
    "\n",
    "with pd.ExcelFile(excel_file_cross) as w:\n",
    "    df_save_under_mean.to_excel(w, sheet_name=name_sheet1)\n",
    "with pd.ExcelFile(excel_file_cross2) as w1:\n",
    "    df_save_under_std.to_excel(w1, sheet_name=name_sheet1)\n",
    "\n",
    "# Visualization results for all models and all datasets\n",
    "for metric in goal:\n",
    "    # Choose metric\n",
    "    df_metric_mean = df_save_under_mean.loc[metric]   # mean\n",
    "    df_metric_std = df_save_under_std.loc[metric]     # std\n",
    "    \n",
    "    max_std = df_metric_std.max()\n",
    "    min_mean = df_metric_mean.min()\n",
    "    ymin = round((min_mean - (max_std + 0.05)),1)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.errorbar(\n",
    "        df_metric_mean.index,                # X: modele\n",
    "        df_metric_mean.values,               # Y: mean\n",
    "        yerr=df_metric_std.values,           # std\n",
    "        fmt=\"o\",                             # marker\n",
    "        ecolor=\"red\", capsize=3,             # color and capsize for error bars\n",
    "        color=\"blue\", label=metric\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Cross-validation mean scores ¬± std for {metric} metric\")\n",
    "    plt.ylim(ymin, 1)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\{metric}_chart.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883195e",
   "metadata": {},
   "source": [
    "### Statistical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9109fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_acc = pd.read_csv(f\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\raw_scores_accuracy.csv\")  \n",
    "row_prec = pd.read_csv(f\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\raw_scores_precision.csv\")\n",
    "row_f1 = pd.read_csv(f\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\raw_scores_f1.csv\")\n",
    "row_recall = pd.read_csv(f\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\raw_scores_recall.csv\")\n",
    "\n",
    "results_cv = {}\n",
    "\n",
    "results_cv[\"accuracy\"] = row_acc\n",
    "results_cv[\"precision\"] = row_prec\n",
    "results_cv[\"f1\"] = row_f1\n",
    "results_cv[\"recall\"] = row_recall\n",
    "\n",
    "for name, df in results_cv.items():\n",
    "    #print(f\"Metric: {name}\")\n",
    "    #print(df.describe())\n",
    "    \n",
    "    anova_res = f_oneway(*(df[model].dropna().values for model in df.columns))\n",
    "    print(f\"Results for ANOVA: {anova_res}\\n\")\n",
    "        \n",
    "    friedman_res = friedmanchisquare(*(df[model].dropna().values for model in df.columns))\n",
    "    print(\"\\nFriedman test results:\")\n",
    "    print(friedman_res)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 4. üìä Boxplot\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.boxplot(data=df)\n",
    "    plt.title(f\"Boxplot for {name} metric\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\stat_analyze\\\\{name}_boxplot.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # 5. üéª Violinplot\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.violinplot(data=df, inner=\"box\")\n",
    "    plt.title(f\"Violinplot for {name} metric\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\stat_analyze\\\\{name}_violinplot.png\", dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "\"\"\"    \n",
    "path = f\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\ssh\\\\results\\\\stat_analyze\\\\stat_results.txt\"\n",
    "\n",
    "    # --- zapis do pliku ---\n",
    "with open(path, \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(\"Statistical analysis results (ANOVA & Friedman)\\n\")\n",
    "    fp.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    for metric_name, df in results_cv.items():\n",
    "      # ANOVA\n",
    "        anova_res = f_oneway(*(df[model].dropna().values for model in df.columns))\n",
    "        # Friedman\n",
    "        friedman_res = friedmanchisquare(*(df[model].dropna().values for model in df.columns))\n",
    "\n",
    "        # zapis wynik√≥w\n",
    "        fp.write(f\"Metric: {metric_name}\\n\")\n",
    "        fp.write(\"-\"*40 + \"\\n\")\n",
    "        fp.write(f\"ANOVA results -> Statistic: {anova_res.statistic:.4f}, \"\n",
    "                 f\"p-value: {anova_res.pvalue:.4e}\\n\")\n",
    "        fp.write(f\"Friedman results -> Statistic: {friedman_res.statistic:.4f}, \"\n",
    "                f\"p-value: {friedman_res.pvalue:.4e}\\n\\n\") \"\"\"\n",
    "\n",
    "# I focuse on f1-score metric, because it is the most important for security incidents detection. Recall is also important to avoid situation when we miss overlook the incident. Main metric is f1-score, the rest is additional information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e127c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posthoc_wilcoxon_bonferroni(df_raw, metric_name):\n",
    "    # --- Friedman test ---\n",
    "    friedman_res = friedmanchisquare(*(df_raw[model].dropna().values for model in df_raw.columns))\n",
    "    print(f\"\\n=== Friedman test for {metric_name} ===\")\n",
    "    print(f\"Statistic={friedman_res.statistic:.3f}, p={friedman_res.pvalue:.3e}\")\n",
    "\n",
    "    results = []\n",
    "    if friedman_res.pvalue <= 0.05:\n",
    "        # --- Wilcoxon test dla ka≈ºdej pary ---\n",
    "        pairs = list(itertools.combinations(df_raw.columns, 2))\n",
    "        for m1, m2 in pairs:\n",
    "            stat, p = wilcoxon(df_raw[m1], df_raw[m2])\n",
    "            results.append({\"Model1\": m1, \"Model2\": m2, \"statistic\": stat, \"pvalue_raw\": p})\n",
    "\n",
    "        df_results = pd.DataFrame(results)\n",
    "\n",
    "        # --- Korekcja Bonferroniego ---\n",
    "        m = len(df_results)\n",
    "        df_results[\"pvalue_corrected\"] = (df_results[\"pvalue_raw\"] * m).clip(upper=1.0)\n",
    "        df_results[\"reject_H0\"] = df_results[\"pvalue_corrected\"] < 0.05\n",
    "        return df_results\n",
    "    else:\n",
    "        print(\"Brak istotnych r√≥≈ºnic wg Friedmana.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def analyze_all_metrics(raw_scores, main_metric=\"f1\"):\n",
    "    \"\"\"\n",
    "    raw_scores: dict {\"metric_name\": DataFrame}, gdzie DataFrame: kolumny=modele, wiersze=foldy\n",
    "    main_metric: metryka, kt√≥ra decyduje o najlepszym modelu (np. \"f1\")\n",
    "    \"\"\"\n",
    "    best_models = {}\n",
    "\n",
    "    with open(\"D:\\\\ml\\\\undersampling_data\\\\reports\\\\unsw\\\\results\\\\stat_analyze\\\\posthoc_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for metric_name, df_raw in results_cv.items():\n",
    "            f.write(f\"\\n### Metric: {metric_name}\\n\")\n",
    "\n",
    "            # statystyki opisowe\n",
    "            desc = df_raw.describe().T[[\"mean\", \"std\"]]\n",
    "            f.write(\"Mean ¬± Std:\\n\")\n",
    "            f.write(desc.to_string())\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "            # testy post-hoc\n",
    "            df_posthoc = posthoc_wilcoxon_bonferroni(df_raw, metric_name)\n",
    "            if df_posthoc is not None:\n",
    "                f.write(\"\\nPost-hoc Wilcoxon + Bonferroni:\\n\")\n",
    "                f.write(df_posthoc.to_string())\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "            # wyb√≥r najlepszego modelu wg ≈õredniej\n",
    "            top_model = desc[\"mean\"].idxmax()\n",
    "            best_models[metric_name] = top_model\n",
    "            f.write(f\"\\nBest model for {metric_name}: {top_model}\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    # wyb√≥r najlepszego modelu wg main_metric\n",
    "    final_best = best_models.get(main_metric)\n",
    "    print(f\"\\n>>> Najlepszy model wg {main_metric.upper()}: {final_best}\")\n",
    "    return final_best\n",
    "\n",
    "\n",
    "# --- przyk≈Çad u≈ºycia ---\n",
    "# raw_scores = {\"accuracy\": df_raw_acc, \"precision\": df_raw_prec, \"recall\": df_raw_rec, \"f1\": df_raw_f1}\n",
    "final_model = analyze_all_metrics(results_cv, main_metric=\"f1\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
