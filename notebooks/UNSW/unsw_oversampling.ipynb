{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b6e87b",
   "metadata": {},
   "source": [
    "# Create synthetic samples from UNSW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ca50a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_23452\\1698480706.py:5: UserWarning: SparkPandasCompare currently only supports Numpy < 2.Please note that the SparkPandasCompare functionality will not work and currently is not supported.\n",
      "  import datacompy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datacompy\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "import gower\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "# narzedzia\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    cross_val_predict,\n",
    "    learning_curve,\n",
    "    RepeatedStratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score, accuracy_score, pairwise_distances, make_scorer, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, f_oneway, friedmanchisquare, wilcoxon\n",
    "from scipy.spatial import distance\n",
    "from joblib import dump, load\n",
    "\n",
    "# modele\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# methods\n",
    "from imblearn.under_sampling import ClusterCentroids, NearMiss\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, HDBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor, KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.spatial.distance import euclidean\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from ctgan import CTGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44dc00d",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc78ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\3554131459.py:2: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_unsw_1 = pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\UNSW-NB15_1.csv')\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\3554131459.py:3: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_unsw_2 = pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\UNSW-NB15_2.csv')\n"
     ]
    }
   ],
   "source": [
    "#df_unsw_features = pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\NUSW-NB15_features.csv')\n",
    "df_unsw_1 = pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\UNSW-NB15_1.csv')\n",
    "df_unsw_2 = pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\UNSW-NB15_2.csv')\n",
    "df_unsw_3 = pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\UNSW-NB15_3.csv')\n",
    "df_unsw_4 = pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\UNSW-NB15_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fae3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "srcip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sport",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "dstip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dsport",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "proto",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "state",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dur",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sbytes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dbytes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sttl",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dttl",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sloss",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dloss",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "service",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sload",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Dload",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Spkts",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dpkts",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "swin",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dwin",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "stcpb",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dtcpb",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "smeansz",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dmeansz",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trans_depth",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "res_bdy_len",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sjit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Djit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Stime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Ltime",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sintpkt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Dintpkt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tcprtt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "synack",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ackdat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_sm_ips_ports",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ct_state_ttl",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ct_flw_http_mthd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_ftp_login",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ct_ftp_cmd",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ct_srv_src",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ct_srv_dst",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ct_dst_ltm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ct_src_ ltm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ct_src_dport_ltm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ct_dst_sport_ltm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ct_dst_src_ltm",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "fbec37e8-15de-48bd-a6d7-45199688d7a0",
       "rows": [
        [
         "0",
         "59.166.0.0",
         "1390",
         "149.171.126.6",
         "53",
         "udp",
         "CON",
         "0.001055",
         "132",
         "164",
         "31",
         "29",
         "0",
         "0",
         "dns",
         "500473.9375",
         "621800.9375",
         "2",
         "2",
         "0",
         "0",
         "0",
         "0",
         "66",
         "82",
         "0",
         "0",
         "0.0",
         "0.0",
         "1421927414",
         "1421927414",
         "0.017",
         "0.013",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0",
         "3",
         "7",
         "1",
         "3",
         "1",
         "1",
         "1",
         "0"
        ],
        [
         "1",
         "59.166.0.0",
         "33661",
         "149.171.126.9",
         "1024",
         "udp",
         "CON",
         "0.036133",
         "528",
         "304",
         "31",
         "29",
         "0",
         "0",
         "-",
         "87676.08594",
         "50480.17188",
         "4",
         "4",
         "0",
         "0",
         "0",
         "0",
         "132",
         "76",
         "0",
         "0",
         "9.89101",
         "10.682733",
         "1421927414",
         "1421927414",
         "7.005",
         "7.564333",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0",
         "2",
         "4",
         "2",
         "3",
         "1",
         "1",
         "2",
         "0"
        ],
        [
         "2",
         "59.166.0.6",
         "1464",
         "149.171.126.7",
         "53",
         "udp",
         "CON",
         "0.001119",
         "146",
         "178",
         "31",
         "29",
         "0",
         "0",
         "dns",
         "521894.5313",
         "636282.375",
         "2",
         "2",
         "0",
         "0",
         "0",
         "0",
         "73",
         "89",
         "0",
         "0",
         "0.0",
         "0.0",
         "1421927414",
         "1421927414",
         "0.017",
         "0.013",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0",
         "12",
         "8",
         "1",
         "2",
         "2",
         "1",
         "1",
         "0"
        ],
        [
         "3",
         "59.166.0.5",
         "3593",
         "149.171.126.5",
         "53",
         "udp",
         "CON",
         "0.001209",
         "132",
         "164",
         "31",
         "29",
         "0",
         "0",
         "dns",
         "436724.5625",
         "542597.1875",
         "2",
         "2",
         "0",
         "0",
         "0",
         "0",
         "66",
         "82",
         "0",
         "0",
         "0.0",
         "0.0",
         "1421927414",
         "1421927414",
         "0.043",
         "0.014",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0",
         "6",
         "9",
         "1",
         "1",
         "1",
         "1",
         "1",
         "0"
        ],
        [
         "4",
         "59.166.0.3",
         "49664",
         "149.171.126.0",
         "53",
         "udp",
         "CON",
         "0.001169",
         "146",
         "178",
         "31",
         "29",
         "0",
         "0",
         "dns",
         "499572.25",
         "609067.5625",
         "2",
         "2",
         "0",
         "0",
         "0",
         "0",
         "73",
         "89",
         "0",
         "0",
         "0.0",
         "0.0",
         "1421927414",
         "1421927414",
         "0.005",
         "0.003",
         "0.0",
         "0.0",
         "0.0",
         "0",
         "0",
         "0.0",
         "0.0",
         "0",
         "7",
         "9",
         "1",
         "1",
         "1",
         "1",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 48,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>149.171.126.6</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>33661</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>1024</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>528</td>\n",
       "      <td>304</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.6</td>\n",
       "      <td>1464</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>3593</td>\n",
       "      <td>149.171.126.5</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>49664</td>\n",
       "      <td>149.171.126.0</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        srcip  sport          dstip dsport proto state       dur  sbytes  \\\n",
       "0  59.166.0.0   1390  149.171.126.6     53   udp   CON  0.001055     132   \n",
       "1  59.166.0.0  33661  149.171.126.9   1024   udp   CON  0.036133     528   \n",
       "2  59.166.0.6   1464  149.171.126.7     53   udp   CON  0.001119     146   \n",
       "3  59.166.0.5   3593  149.171.126.5     53   udp   CON  0.001209     132   \n",
       "4  59.166.0.3  49664  149.171.126.0     53   udp   CON  0.001169     146   \n",
       "\n",
       "   dbytes  sttl  ...  is_ftp_login  ct_ftp_cmd  ct_srv_src ct_srv_dst  \\\n",
       "0     164    31  ...           0.0           0           3          7   \n",
       "1     304    31  ...           0.0           0           2          4   \n",
       "2     178    31  ...           0.0           0          12          8   \n",
       "3     164    31  ...           0.0           0           6          9   \n",
       "4     178    31  ...           0.0           0           7          9   \n",
       "\n",
       "   ct_dst_ltm  ct_src_ ltm  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
       "0           1            3                 1                 1   \n",
       "1           2            3                 1                 1   \n",
       "2           1            2                 2                 1   \n",
       "3           1            1                 1                 1   \n",
       "4           1            1                 1                 1   \n",
       "\n",
       "   ct_dst_src_ltm  Label  \n",
       "0               1      0  \n",
       "1               2      0  \n",
       "2               1      0  \n",
       "3               1      0  \n",
       "4               1      0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unsw = pd.concat([df_unsw_1, df_unsw_2, df_unsw_3, df_unsw_4], ignore_index=True)\n",
    "df_unsw = df_unsw.drop(columns=['attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b1234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n",
      "C:\\Users\\mateu\\AppData\\Local\\Temp\\ipykernel_20668\\2688879982.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_other_ports[col] = 0\n"
     ]
    }
   ],
   "source": [
    "# what to do with ports? src drop because is random, dst - keep because is related to service, port number >1000 is random\n",
    "def to_int_or_hex(x):\n",
    "    try:\n",
    "        if isinstance(x, (int, float)) and not pd.isna(x):\n",
    "            return int(x)\n",
    "        elif isinstance(x, str) and x.startswith('0x'):\n",
    "            return int(x, 16)\n",
    "        elif isinstance(x, str):\n",
    "            return int(x)\n",
    "        else:\n",
    "            return pd.NA\n",
    "    except ValueError:\n",
    "        return pd.NA\n",
    "\n",
    "df_unsw['dsport'] = df_unsw['dsport'].apply(to_int_or_hex).astype('Int64')\n",
    "\n",
    "mask_well_known = df_unsw['dsport'] <= 1000\n",
    "df_well_known = df_unsw[mask_well_known].copy()\n",
    "df_other_ports = df_unsw[~mask_well_known].copy()\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_ports = encoder.fit_transform(df_well_known[['dsport']])\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_ports,\n",
    "    columns=encoder.get_feature_names_out(['dsport']),\n",
    "    index=df_well_known.index\n",
    ")\n",
    "\n",
    "df_well_known = pd.concat([encoded_df, df_well_known.drop(columns=['dsport'])], axis=1)\n",
    "\n",
    "df_other_ports['dsport_other'] = 1\n",
    "\n",
    "for col in df_well_known.columns:\n",
    "    if col not in df_other_ports.columns:\n",
    "        df_other_ports[col] = 0\n",
    "\n",
    "df_unsw = pd.concat([df_well_known, df_other_ports], axis=0).sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382de5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 'dsport_other' next to 'proto' and fill NaN with 0\n",
    "col = df_unsw.pop('dsport_other')\n",
    "dst_col = df_unsw.columns.get_loc('proto')\n",
    "df_unsw.insert(dst_col, 'dsport_other', col)\n",
    "df_unsw['dsport_other'] = df_unsw['dsport_other'].fillna(0)\n",
    "df_unsw = df_unsw.drop(columns=['dsport', 'srcip', 'dstip', 'sport'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2895eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" proto_index = df_unsw.columns.get_loc('proto')\\n\\nfor i, col in enumerate(df_proto.columns):\\n    df_unsw.insert(proto_index + 1 + i, col, df_unsw[col]) \""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_unsw['proto_simplified'] = df_unsw['proto'].apply(\n",
    "    lambda x: x if x in ['tcp', 'udp'] else 'other'\n",
    ")\n",
    "\n",
    "df_unsw = pd.get_dummies(df_unsw, columns=['proto_simplified'], prefix='proto')\n",
    "#df_unsw = df_unsw.loc[:, ~df_unsw.columns.duplicated(keep='first')]\n",
    "\n",
    "col = df_unsw.pop('proto_other')\n",
    "col2 = df_unsw.pop('proto_tcp')\n",
    "col3 = df_unsw.pop('proto_udp')\n",
    "dst_col = df_unsw.columns.get_loc('state')\n",
    "df_unsw.insert(dst_col, 'proto_other', col)\n",
    "df_unsw.insert(dst_col + 1, 'proto_tcp', col2)\n",
    "df_unsw.insert(dst_col + 2, 'proto_udp', col3)\n",
    "\n",
    "df_unsw = df_unsw.drop(columns=['proto'])\n",
    "\n",
    "df_unsw.loc[:, df_unsw.columns.str.startswith('proto')] = (\n",
    "    df_unsw.loc[:, df_unsw.columns.str.startswith('proto')].astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_ports = encoder.fit_transform(df_unsw[['proto']])\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_ports,\n",
    "    columns=encoder.get_feature_names_out(['proto']),\n",
    "    index=df_unsw.index\n",
    ")\n",
    "proto_index = df_unsw.columns.get_loc('proto')\n",
    "\n",
    "for i, col in enumerate(encoded_df.columns):\n",
    "    df_unsw.insert(proto_index + 1 + i, col, encoded_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42effe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced protocols to tcp, udp, other\n",
    "df_unsw['proto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96828d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsw = pd.get_dummies(df_unsw, columns=['proto'], prefix='proto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b0883d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_normalize = [\n",
    "    'dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss',\n",
    "    'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb',\n",
    "    'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit',\n",
    "    'Stime', 'Ltime', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat',\n",
    "    'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', \n",
    "    'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm',\n",
    "    'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_unsw[cols_to_normalize] = scaler.fit_transform(df_unsw[cols_to_normalize])\n",
    "\n",
    "with open(f\"D:\\\\ml\\\\undersampling_data\\\\models\\\\unsw\\\\scaler.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fc72289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsw.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "df_unsw['ct_ftp_cmd'] = df_unsw['ct_ftp_cmd'].fillna(0)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "df_unsw[['ct_ftp_cmd']] = scaler2.fit_transform(df_unsw[['ct_ftp_cmd']])\n",
    "\n",
    "with open(f\"D:\\\\ml\\\\undersampling_data\\\\models\\\\unsw\\\\scaler_ct_ftp_cmd.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92f69d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_states = ['FIN', 'CON', 'INT', 'REQ', 'RST', 'CLO', 'ACC']\n",
    "df_unsw = df_unsw[df_unsw['state'].isin(valid_states)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bbef502",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_state = encoder.fit_transform(df_unsw[['state']])\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_state,\n",
    "    columns=encoder.get_feature_names_out(['state']),\n",
    "    index=df_unsw.index\n",
    ")\n",
    "state_index = df_unsw.columns.get_loc('state')\n",
    "\n",
    "for i, col in enumerate(encoded_df.columns):\n",
    "    df_unsw.insert(state_index + 1 + i, col, encoded_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6918834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsw = pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\UNSW-NB15_processed_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ab6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsw['dsport_20.0'] = (df_unsw['service'] == 'ftp-data').astype(int)\n",
    "\n",
    "col = df_unsw.pop('dsport_20.0')\n",
    "dst_col = df_unsw.columns.get_loc('dsport_21.0')\n",
    "df_unsw.insert(dst_col, 'dsport_20.0', col)\n",
    "\n",
    "df_unsw = df_unsw[~df_unsw['service'].isin(['radius', 'irc'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsw['ct_flw_http_mthd'] = df_unsw['ct_flw_http_mthd'].fillna(0)\n",
    "df_unsw['is_ftp_login'] = df_unsw['is_ftp_login'].fillna(0)\n",
    "df_unsw = df_unsw.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_unsw = df_unsw.drop(columns=['service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd0c7517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1432298, 161), (613842, 161))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_unsw.drop(columns=['Label'])\n",
    "y = df_unsw['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,        # 20% danych do testu\n",
    "    random_state=42,      # dla powtarzalności\n",
    "    stratify=y            # zachowaj proporcje klas\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['service'])\n",
    "X_test = X_test.drop(columns=['service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e26d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\X_train.csv', index=False)\n",
    "X_test.to_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\X_test.csv', index=False)\n",
    "y_train.to_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\y_train.csv', index=False)\n",
    "y_test.to_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\y_test.csv', index=False)\n",
    "df_unsw.to_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\UNSW-NB15_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6dabe8",
   "metadata": {},
   "source": [
    "### Oversamling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54bb0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\X_train.csv')\n",
    "y_train = pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e6d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92cf10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\UNSW-NB15_train_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db27e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 1370400, 1: 61898})\n",
      "After Counter({0: 1370400, 1: 1370400})\n",
      "After generation 3x SMOTE Counter({1: 2678902, 0: 1370400})\n"
     ]
    }
   ],
   "source": [
    "file_path1 = \"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\oversampling\\\\smote_data.csv\"\n",
    "file_path2 = \"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\oversampling\\\\smote3_data.csv\"\n",
    "#zamiana jesli istnieje to wczytaj plik jesli nie to stworz\n",
    "coun = Counter(y_train)\n",
    "majority_class = max(coun, key=coun.get)\n",
    "minority_class = min(coun, key=coun.get)\n",
    "missing_samples = coun[majority_class] - coun[minority_class]\n",
    "print(\"Before\", coun)\n",
    "smote = SMOTE()\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "smote2 = SMOTE(sampling_strategy={minority_class: coun[minority_class] + 2 * missing_samples}, random_state=42)\n",
    "X_train_sm3, y_train_sm3 = smote2.fit_resample(X_train, y_train)\n",
    "\n",
    "train_data_smote = pd.concat([X_train_sm, y_train_sm], axis=1)          #polaczenie danych wygenerowanych X_train oraz y_train\n",
    "train_data_smote3 = pd.concat([X_train_sm3, y_train_sm3], axis=1)\n",
    "\n",
    "#smote generated data\n",
    "train_data_smote['generated_by_smote'] = ['original' if i < len(df) else 'smote' for i in range(len(train_data_smote))]\n",
    "smote_data = train_data_smote[train_data_smote['generated_by_smote'] == 'smote'].drop('generated_by_smote', axis=1)\n",
    "smote_data[\"source\"] = \"smote\"\n",
    "if not os.path.exists(file_path1):\n",
    "    smote_data.to_csv(file_path1, index=False)\n",
    "else:\n",
    "    print(f'Plik istnieje pod ścieżką: {file_path1}')\n",
    "\n",
    "#smote3 generated data\n",
    "train_data_smote3['generated_by_smote'] = ['original' if i < len(df) else 'smote' for i in range(len(train_data_smote3))]\n",
    "smote_data3 = train_data_smote3[train_data_smote3['generated_by_smote'] == 'smote'].drop('generated_by_smote', axis=1)\n",
    "smote_data3[\"source\"] = \"smote\"\n",
    "if not os.path.exists(file_path2):\n",
    "    smote_data3.to_csv(file_path2, index=False)\n",
    "else:\n",
    "    print(f'Plik istnieje pod ścieżką: {file_path2}')\n",
    "\n",
    "con1 = Counter(y_train_sm)\n",
    "print(\"After\", con1)\n",
    "con2 = Counter(y_train_sm3)\n",
    "print(\"After generation 3x SMOTE\", con2)\n",
    "#pd.Series(y_train_sm).value_counts().plot.bar()\n",
    "#pd.Series(y_train_sm3).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b376d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0        1370400\n",
      "1          61898\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "coun3 = Counter(y_train)\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 1370400, 1: 61898})\n",
      "After Counter({'Label': 1})\n",
      "After generated 3x BorderlineSMOTE Counter({'Label': 1})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional, got ndarray of shape (2740800, 1) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlik istnieje pod ścieżką: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_bsm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar()\n\u001b[0;32m     46\u001b[0m pd\u001b[38;5;241m.\u001b[39mSeries(y_train_bsm3)\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mbar()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\construction.py:633\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    642\u001b[0m     _sanitize_non_ordered(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\construction.py:659\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    656\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[0;32m    657\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 659\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    663\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\construction.py:718\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    720\u001b[0m     )\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (2740800, 1) instead"
     ]
    }
   ],
   "source": [
    "file_path2 = \"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\oversampling\\\\borderline_data.csv\"\n",
    "file_path1 = \"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\oversampling\\\\borderline3_data.csv\"\n",
    "#generate new data by borderLineSMOTE\n",
    "coun3 = Counter(y_train['Label'])\n",
    "majority_class = max(coun3, key=coun3.get)\n",
    "minority_class = min(coun3, key=coun3.get)\n",
    "missing_samples = coun3[majority_class] - coun3[minority_class]\n",
    "print(\"Before\", coun3)\n",
    "\n",
    "brdsmote = BorderlineSMOTE(random_state=42)\n",
    "X_train_bsm, y_train_bsm = brdsmote.fit_resample(X_train, y_train)\n",
    "\n",
    "brdsmote3 = BorderlineSMOTE(sampling_strategy={minority_class: coun3[minority_class] + 2 * missing_samples}, random_state=42)\n",
    "X_train_bsm3, y_train_bsm3 = brdsmote3.fit_resample(X_train, y_train)\n",
    "\n",
    "con4 = Counter(y_train_bsm)\n",
    "print(\"After\", con4)\n",
    "con5 = Counter(y_train_bsm3)\n",
    "print(\"After generated 3x BorderlineSMOTE\", con5)\n",
    "\n",
    "train_data_borderline_smote = pd.concat([X_train_bsm, y_train_bsm], axis=1)          #polaczenie danych wygenerowanych X_train oraz y_train\n",
    "train_data_borderline_smote3 = pd.concat([X_train_bsm3, y_train_bsm3], axis=1)\n",
    "\n",
    "#borderline smote generated data\n",
    "train_data_borderline_smote['generated_by_borderline_smote'] = ['original' if i < len(df) else 'brd smote' for i in range(len(train_data_borderline_smote))]\n",
    "boarderline_smote_data = train_data_borderline_smote[train_data_borderline_smote['generated_by_borderline_smote'] == 'brd smote'].drop('generated_by_borderline_smote', axis=1)\n",
    "boarderline_smote_data[\"source\"]=\"borderline smote\"\n",
    "boarderline_smote_data = boarderline_smote_data[boarderline_smote_data['source'] != 'original']\n",
    "if not os.path.exists(file_path2):\n",
    "    boarderline_smote_data.to_csv(file_path2, index=False)\n",
    "else:\n",
    "    print(f'Plik istnieje pod ścieżką: {file_path2}')\n",
    "    \n",
    "#borderline smote3 generated data\n",
    "train_data_borderline_smote3['generated_by_borderline_smote'] = ['original' if i < len(df) else 'brd smote' for i in range(len(train_data_borderline_smote3))]\n",
    "boarderline_smote_data3 = train_data_borderline_smote3[train_data_borderline_smote3['generated_by_borderline_smote'] == 'brd smote'].drop('generated_by_borderline_smote', axis=1)\n",
    "boarderline_smote_data3[\"source\"]=\"borderline smote\"\n",
    "boarderline_smote_data3 = boarderline_smote_data3[boarderline_smote_data3['source'] != 'original']\n",
    "if not os.path.exists(file_path1):\n",
    "    boarderline_smote_data3.to_csv(file_path1, index=False)\n",
    "else:\n",
    "    print(f'Plik istnieje pod ścieżką: {file_path1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbdb85a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\mateu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\mateu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 215, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"C:\\Users\\mateu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 208, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"C:\\Users\\mateu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 1245, in dump\n    return super().dump(obj)\n           ^^^^^^^^^^^^^^^^^\nMemoryError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_num[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m target_num[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     14\u001b[0m     data_y1 \u001b[38;5;241m=\u001b[39m df_gan[df_gan[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mctgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_y1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(target_num[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39mtarget_num[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     17\u001b[0m     df_GAN \u001b[38;5;241m=\u001b[39m ctgan\u001b[38;5;241m.\u001b[39msample(sample)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\synthesizers\\base.py:50\u001b[0m, in \u001b[0;36mrandom_state.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m set_random_states(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_random_state):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\synthesizers\\ctgan.py:348\u001b[0m, in \u001b[0;36mCTGAN.fit\u001b[1;34m(self, train_data, discrete_columns, epochs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer \u001b[38;5;241m=\u001b[39m DataTransformer()\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer\u001b[38;5;241m.\u001b[39mfit(train_data, discrete_columns)\n\u001b[1;32m--> 348\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_sampler \u001b[38;5;241m=\u001b[39m DataSampler(\n\u001b[0;32m    351\u001b[0m     train_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer\u001b[38;5;241m.\u001b[39moutput_info_list, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_frequency\n\u001b[0;32m    352\u001b[0m )\n\u001b[0;32m    354\u001b[0m data_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer\u001b[38;5;241m.\u001b[39moutput_dimensions\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\data_transformer.py:187\u001b[0m, in \u001b[0;36mDataTransformer.transform\u001b[1;34m(self, raw_data)\u001b[0m\n\u001b[0;32m    183\u001b[0m     column_data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_synchronous_transform(\n\u001b[0;32m    184\u001b[0m         raw_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_transform_info_list\n\u001b[0;32m    185\u001b[0m     )\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     column_data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_column_transform_info_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(column_data_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\data_transformer.py:172\u001b[0m, in \u001b[0;36mDataTransformer._parallel_transform\u001b[1;34m(self, raw_data, column_transform_info_list)\u001b[0m\n\u001b[0;32m    169\u001b[0m         process \u001b[38;5;241m=\u001b[39m delayed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_discrete)(column_transform_info, data)\n\u001b[0;32m    170\u001b[0m     processes\u001b[38;5;241m.\u001b[39mappend(process)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "file_path3 = \"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\oversampling\\\\GAN_data.csv\"        #sciezka wraz z nazwa pod jaka wygenerowac plik\n",
    "file_path4 = \"D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\oversampling\\\\GAN3_data.csv\"        #sciezka wraz z nazwa pod jaka wygenerowac plik\n",
    "#generate new data by GAN\n",
    "\n",
    "#data preparation\n",
    "df_gan = df\n",
    "\n",
    "#GAN\n",
    "columns_list = df_gan.columns\n",
    "target_num = df_gan['Label'].value_counts()\n",
    "ctgan = CTGAN(epochs=100, batch_size=128, cuda=True)        #model\n",
    "\n",
    "if target_num[0] > target_num[1]:\n",
    "    data_y1 = df_gan[df_gan['Label']==1]\n",
    "    ctgan.fit(data_y1, columns_list)\n",
    "    sample = abs(target_num[0]-target_num[1])\n",
    "    df_GAN = ctgan.sample(sample)\n",
    "    print('Dane wygenerowane: ', df_GAN['Label'].value_counts())\n",
    "    balanced_data = pd.concat([df_gan, df_GAN], ignore_index=False)\n",
    "else:\n",
    "    data_y0 = df_gan[df_gan['Label']==0]\n",
    "    ctgan.fit(data_y0, columns_list)\n",
    "    sample = abs(target_num[0]-target_num[1])\n",
    "    df_GAN = ctgan.sample(sample)\n",
    "    print('Dane wygenerowane: ', df_GAN['Label'].value_counts())\n",
    "    balanced_data = pd.concat([df_gan, df_GAN], ignore_index=False)\n",
    "\n",
    "#GAN3\n",
    "if target_num[0] > target_num[1]:\n",
    "    data_y1 = df_gan[df_gan['Label']==1]\n",
    "    ctgan.fit(data_y1, columns_list)\n",
    "    sample = abs(target_num[0]-target_num[1])\n",
    "    df_GAN3 = ctgan.sample(sample*2)\n",
    "    print('Dane wygenerowane: ', df_GAN3['Label'].value_counts())\n",
    "    balanced_data3 = pd.concat([df_gan, df_GAN3], ignore_index=False)\n",
    "else:\n",
    "    data_y0 = df_gan[df_gan['Label']==0]\n",
    "    ctgan.fit(data_y0, columns_list)\n",
    "    sample = abs(target_num[0]-target_num[1])\n",
    "    df_GAN3 = ctgan.sample(sample*2)\n",
    "    print('Dane wygenerowane: ', df_GAN3['Label'].value_counts())\n",
    "    balanced_data3 = pd.concat([df_gan, df_GAN3], ignore_index=False)\n",
    "\n",
    "#balanced_data = balanced_data.drop(columns=[\"source\"])  \n",
    "y_train_gan = balanced_data[\"Label\"]\n",
    "X_train_gan = balanced_data.drop(columns=[\"Label\"])\n",
    "\n",
    "#GAN3\n",
    "y_train_gan3 = balanced_data3[\"Label\"]\n",
    "X_train_gan3 = balanced_data3.drop(columns=[\"Label\"])\n",
    "con5 = Counter(y_train)\n",
    "print(\"Before\", con5)\n",
    "con6 = Counter(y_train_gan)\n",
    "print(\"After\", con6)\n",
    "gan_data = df_GAN\n",
    "con7 = Counter(y_train_gan3)\n",
    "print(\"After\", con7)\n",
    "gan_data3 = df_GAN3\n",
    "\n",
    "gan_data[\"source\"] = \"gan\"\n",
    "if not os.path.exists(file_path3):\n",
    "    gan_data.to_csv(file_path3, index=False)\n",
    "else:\n",
    "    print(f'Plik istnieje pod ścieżką: {file_path3}')\n",
    "    \n",
    "gan_data3[\"source\"] = \"gan\"\n",
    "if not os.path.exists(file_path4):\n",
    "    gan_data3.to_csv(file_path4, index=False)\n",
    "else:\n",
    "    print(f'Plik istnieje pod ścieżką: {file_path4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc0a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (0.00) | Discrim. (0.00):   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 95\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 71\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Alternatywnie:\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# from ctgan import CTGANSynthesizer\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# ctgan = CTGANSynthesizer(epochs=EPOCHS, batch_size=BATCH_SIZE, cuda=USE_CUDA)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# 6) Trening tylko na klasie mniejszości (by generować próbki tej klasy)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m ctgan\u001b[38;5;241m.\u001b[39mset_random_state(RANDOM_STATE) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ctgan, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_random_state\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[43mctgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscrete_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# 7) Generowanie brakujących próbek klasy mniejszości\u001b[39;00m\n\u001b[0;32m     74\u001b[0m df_synth \u001b[38;5;241m=\u001b[39m ctgan\u001b[38;5;241m.\u001b[39msample(gap)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\synthesizers\\base.py:54\u001b[0m, in \u001b[0;36mrandom_state.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_random_states(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_random_state):\n\u001b[1;32m---> 54\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\synthesizers\\ctgan.py:425\u001b[0m, in \u001b[0;36mCTGAN.fit\u001b[1;34m(self, train_data, discrete_columns, epochs)\u001b[0m\n\u001b[0;32m    422\u001b[0m     real_cat \u001b[38;5;241m=\u001b[39m real\n\u001b[0;32m    423\u001b[0m     fake_cat \u001b[38;5;241m=\u001b[39m fakeact\n\u001b[1;32m--> 425\u001b[0m y_fake \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_cat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    426\u001b[0m y_real \u001b[38;5;241m=\u001b[39m discriminator(real_cat)\n\u001b[0;32m    428\u001b[0m pen \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mcalc_gradient_penalty(\n\u001b[0;32m    429\u001b[0m     real_cat, fake_cat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpac\n\u001b[0;32m    430\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ctgan\\synthesizers\\ctgan.py:60\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, input_)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply the Discriminator to the `input_`.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m input_\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpac \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq(input_\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpacdim))\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# balance_with_ctgan.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from ctgan import CTGAN  # możesz użyć też: from ctgan import CTGANSynthesizer\n",
    "import multiprocessing as mp\n",
    "\n",
    "# --- KONFIG ---\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64          # jeśli OOM: 128 -> 64\n",
    "RANDOM_STATE = 42         # powtarzalność\n",
    "USE_CUDA = True           # GPU\n",
    "\n",
    "def infer_discrete_columns(df: pd.DataFrame):\n",
    "    \"\"\"Zbuduj listę kolumn dyskretnych dla CTGAN (kategorie/boole/label).\"\"\"\n",
    "    discrete = []\n",
    "    for c in df.columns:\n",
    "        dt = str(df[c].dtype)\n",
    "        if dt in (\"object\", \"bool\") or \"category\" in dt:\n",
    "            discrete.append(c)\n",
    "    # Upewnij się, że 'Label' jest traktowana jako dyskretna\n",
    "    if \"Label\" in df.columns and \"Label\" not in discrete:\n",
    "        discrete.append(\"Label\")\n",
    "    return discrete\n",
    "\n",
    "def main():\n",
    "    # 1) Wczytaj dane\n",
    "    # Podmień na swoją ścieżkę:\n",
    "    df_gan = pd.read_parquet(\"data.parquet\") if os.path.exists(\"data.parquet\") else pd.read_csv('D:\\\\ml\\\\undersampling_data\\\\data\\\\unsw\\\\UNSW-NB15_train_final.csv')\n",
    "\n",
    "    # Upewnij się, że Label jest int/kat.\n",
    "    if df_gan[\"Label\"].dtype != \"int64\" and df_gan[\"Label\"].dtype != \"int32\":\n",
    "        try:\n",
    "            df_gan[\"Label\"] = df_gan[\"Label\"].astype(\"int32\")\n",
    "        except Exception:\n",
    "            df_gan[\"Label\"] = df_gan[\"Label\"].astype(\"category\")\n",
    "\n",
    "    # 2) Wyznacz klasy mniejszości/większości poprawnie\n",
    "    counts = df_gan[\"Label\"].value_counts()\n",
    "    minority = counts.idxmin()\n",
    "    majority = counts.idxmax()\n",
    "    n_min, n_maj = counts[minority], counts[majority]\n",
    "    gap = int(n_maj - n_min)\n",
    "\n",
    "    if gap <= 0:\n",
    "        print(\"Zbiór już zbalansowany:\", counts.to_dict())\n",
    "        return\n",
    "\n",
    "    # 3) Dane klasy mniejszości do treningu CTGAN\n",
    "    data_min = df_gan[df_gan[\"Label\"] == minority].copy()\n",
    "\n",
    "    # 4) Lista dyskretnych kolumn (NIE wszystkie kolumny!)\n",
    "    discrete_cols = infer_discrete_columns(df_gan)\n",
    "    # Opcjonalnie doprecyzuj: jeśli masz kategorie zakodowane liczbowo, dołóż je ręcznie:\n",
    "    # discrete_cols += [\"kolumna_kat_1\", \"kolumna_kat_2\"]\n",
    "\n",
    "    # 5) Model CTGAN na GPU\n",
    "    ctgan = CTGAN(\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        generator_dim=(256, 256),\n",
    "        discriminator_dim=(256, 256),\n",
    "        cuda=USE_CUDA,\n",
    "        verbose=True\n",
    "    )\n",
    "    # Alternatywnie:\n",
    "    # from ctgan import CTGANSynthesizer\n",
    "    # ctgan = CTGANSynthesizer(epochs=EPOCHS, batch_size=BATCH_SIZE, cuda=USE_CUDA)\n",
    "\n",
    "    # 6) Trening tylko na klasie mniejszości (by generować próbki tej klasy)\n",
    "    ctgan.set_random_state(RANDOM_STATE) if hasattr(ctgan, \"set_random_state\") else None\n",
    "    ctgan.fit(data_min, discrete_columns=discrete_cols)\n",
    "\n",
    "    # 7) Generowanie brakujących próbek klasy mniejszości\n",
    "    df_synth = ctgan.sample(gap)\n",
    "    # Upewnij się, że wygenerowana etykieta to mniejszość (przy treningu na jednej klasie powinna być stała)\n",
    "    if \"Label\" in df_synth.columns:\n",
    "        df_synth[\"Label\"] = minority\n",
    "\n",
    "    print(\"Oryginalne klasy:\", counts.to_dict())\n",
    "    print(\"Wygenerowane (Label counts):\", df_synth[\"Label\"].value_counts().to_dict())\n",
    "\n",
    "    # 8) Sklejenie i wynik\n",
    "    balanced = pd.concat([df_gan, df_synth], ignore_index=True)\n",
    "    print(\"Po zbalansowaniu:\", balanced[\"Label\"].value_counts().to_dict())\n",
    "\n",
    "    balanced.to_parquet(\"balanced.parquet\", index=False)\n",
    "    print(\"Zapisano: balanced.parquet\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Na Windows błąd picklowania znika dzięki spawn + guard:\n",
    "    try:\n",
    "        mp.set_start_method(\"spawn\", force=True)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
