{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6301aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datacompy\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# narzedzia\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    cross_val_predict,\n",
    "    learning_curve,\n",
    "    RepeatedStratifiedKFold,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from joblib import dump, load\n",
    "\n",
    "# modele\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# methods\n",
    "from imblearn.under_sampling import ClusterCentroids, NearMiss\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor, KNeighborsClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.spatial.distance import euclidean\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "#from ctgan import CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b861e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    151\n",
      "1     46\n",
      "Name: count, dtype: int64\n",
      "197\n",
      "Before undersampling: 105\n",
      "After number of samples: 302\n"
     ]
    }
   ],
   "source": [
    "#oversampling data\n",
    "original_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\original_data.csv\")    \n",
    "original_data = original_data.drop(columns=[\"Unnamed: 0\"])\n",
    "smote_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\smote_data.csv\")\n",
    "GAN_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\GAN_data.csv\")\n",
    "borderline_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\borderline_data.csv\")\n",
    "smote2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\smote3_data.csv\")\n",
    "GAN2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\GAN3_data.csv\")    \n",
    "borderline2_data = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\borderline3_data.csv\")\n",
    "\n",
    "# test data\n",
    "X_test = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\test\\\\X_test.csv\")\n",
    "y_test = pd.read_csv(\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\test\\\\y_test.csv\")\n",
    "\n",
    "#Before undersampling\n",
    "print(original_data[\"target\"].value_counts())\n",
    "count1=original_data[\"target\"].value_counts().sum()\n",
    "print(count1)\n",
    "count2=abs((original_data['target']==0).sum() - (original_data['target']==1).sum())\n",
    "print(f\"Before undersampling: {count2}\")\n",
    "print(f\"After number of samples: {count1+count2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0973a167",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c318c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed data\n",
    "mix_data = pd.concat([GAN_data, smote_data, borderline_data, original_data], axis=0, ignore_index=True)         \n",
    "mix_data = mix_data.reset_index(drop=True)\n",
    "\n",
    "#data with one oversampling method and original data e.g.(smote+original)\n",
    "smote_data = pd.concat([smote_data, smote2_data, original_data], axis=0, ignore_index=True)\n",
    "smote_data = smote_data.reset_index(drop=True)\n",
    "borderline_data = pd.concat([borderline_data, borderline2_data, original_data], axis=0, ignore_index=True)\n",
    "borderline_data = borderline_data.reset_index(drop=True)\n",
    "GAN_data = pd.concat([GAN_data, GAN2_data, original_data], axis=0, ignore_index=True)\n",
    "GAN_data = GAN_data.reset_index(drop=True)\n",
    "\n",
    "sum_all_data = pd.concat([smote_data, GAN_data, borderline_data, original_data], axis=0, ignore_index=True)\n",
    "sum_all_data = sum_all_data.drop_duplicates()\n",
    "\n",
    "\n",
    "#Split data\n",
    "X_mix, y_mix = mix_data.drop(columns=[\"target\", \"source\"]), mix_data[\"target\"]\n",
    "X_smote, y_smote = smote_data.drop(columns=[\"target\", \"source\"]), smote_data[\"target\"]\n",
    "X_GAN, y_GAN = GAN_data.drop(columns=[\"target\", \"source\"]), GAN_data[\"target\"]\n",
    "X_borderline, y_borderline = borderline_data.drop(columns=[\"target\", \"source\"]), borderline_data[\"target\"]\n",
    "\n",
    "#Dictionary\n",
    "data = {}\n",
    "data[\"mix\"] = (X_mix, y_mix)\n",
    "data[\"smote\"] = (X_smote, y_smote)\n",
    "data[\"GAN\"] = (X_GAN, y_GAN)\n",
    "data[\"borderline\"] = (X_borderline, y_borderline)\n",
    "\n",
    "compare = {}\n",
    "compare[\"mix\"] = mix_data\n",
    "compare[\"smote\"] = smote_data\n",
    "compare[\"GAN\"] = GAN_data\n",
    "compare[\"borderline\"] = borderline_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9702ef0",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec82b04",
   "metadata": {},
   "source": [
    "#### K-means + centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33ff4561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for mix data\n",
      "target\n",
      "1    151\n",
      "0    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for smote data\n",
      "target\n",
      "1    151\n",
      "0    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for GAN data\n",
      "target\n",
      "1    151\n",
      "0    151\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced for borderline data\n",
      "target\n",
      "1    151\n",
      "0    151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "KM = KMeans(n_clusters=(int)((count1+count2)/2))\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "    \n",
    "    X_majority = X_train[y_train == 1]\n",
    "    X_minority = X_train[y_train == 0]\n",
    "    \n",
    "    kmeans = KM.fit(X_majority)\n",
    "    \n",
    "    X_majority_reduced = pd.DataFrame(kmeans.cluster_centers_, columns=X_train.columns)\n",
    "    y_majority_reduced = pd.Series([1] * (int)((count1+count2)/2), name=\"target\") \n",
    "    \n",
    "    X_minority = X_minority.reset_index(drop=True)\n",
    "    y_minority = pd.Series([0] * len(X_minority), name=\"target\")\n",
    "    \n",
    "    X_final = pd.concat([X_majority_reduced, X_minority], axis=0).reset_index(drop=True) \n",
    "    y_final = pd.concat([y_majority_reduced, y_minority], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Concat resampled data\n",
    "    reduced_data = pd.concat([X_final, y_final], axis=1)\n",
    "    \n",
    "    reduced_data[\"source\"] = None  # Initialize the source column with None\n",
    "    \n",
    "    # gdy target = 1 wtedy source = \"centroid\", inaczej source = \"original\"\n",
    "    \n",
    "    # Compare data to copy source column\n",
    "    data_nosource = compare_df\n",
    "    reduced_data_nosource = reduced_data\n",
    "\n",
    "    # Iterate through the rows in reduced_data_nosource\n",
    "    for index, row in reduced_data_nosource.iterrows():\n",
    "        match = data_nosource.eq(row).all(axis=1)  # Check where rows are identical\n",
    "        if match.any():  # If a match is found\n",
    "            matched_index = match.idxmax()  # Get the first matching index\n",
    "            reduced_data.loc[index, \"source\"] = compare_df.loc[matched_index, \"source\"]\n",
    "            \n",
    "    # Check for any rows that still have None in the source column\n",
    "    missing_source = reduced_data[reduced_data[\"source\"].isna()]\n",
    "    if not missing_source.empty:\n",
    "        reduced_data.loc[reduced_data[\"source\"].isna(), \"source\"] = \"centroid\"       \n",
    "    \n",
    "    reduced_data.to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_KM_centroids_data.csv\", index=False)\n",
    "    \n",
    "    print(f\"Data reduced for {name} data\")\n",
    "    print(reduced_data[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda4f00d",
   "metadata": {},
   "source": [
    "#### K-means + the nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5ffbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user  is_private  is_failure  is_root  is_valid  not_valid_count  \\\n",
      "0       4           1           1        0         0                8   \n",
      "1      31           1           1        0         0               10   \n",
      "2      15           1           1        0         0                6   \n",
      "3      30           1           1        0         0               14   \n",
      "4      26           1           1        0         0                0   \n",
      "..    ...         ...         ...      ...       ...              ...   \n",
      "297    30           1           1        1         1                0   \n",
      "298    30           1           0        0         1                0   \n",
      "299    24           1           0        0         1                0   \n",
      "300    18           1           0        0         1                0   \n",
      "301    30           1           0        0         1                0   \n",
      "\n",
      "     ip_failure  ip_success  no_failure  first    td        ts  target  \\\n",
      "0             9           0          14      0     5 -0.687180       1   \n",
      "1            12          11           8      0  1465  0.533977       1   \n",
      "2             7           5          10      0   729  0.530738       1   \n",
      "3            14          14           8      0  1803  0.540408       1   \n",
      "4             6           1           9      0   284  0.520568       1   \n",
      "..          ...         ...         ...    ...   ...       ...     ...   \n",
      "297           3           2           4      0     1  0.511124       0   \n",
      "298           0           4           0      0    26  0.512363       0   \n",
      "299           0           9           0      0     9  0.538242       0   \n",
      "300           0          33           0      0     8  0.540250       0   \n",
      "301           0          12           0      0    33  0.511790       0   \n",
      "\n",
      "               source  \n",
      "0               smote  \n",
      "1               smote  \n",
      "2    borderline smote  \n",
      "3            original  \n",
      "4               smote  \n",
      "..                ...  \n",
      "297          original  \n",
      "298          original  \n",
      "299          original  \n",
      "300          original  \n",
      "301          original  \n",
      "\n",
      "[302 rows x 14 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user  is_private  is_failure  is_root  is_valid  not_valid_count  \\\n",
      "0      11           1           1        0         0                0   \n",
      "1      37           1           1        0         0                1   \n",
      "2      37           1           1        0         0                0   \n",
      "3      24           1           1        0         0                1   \n",
      "4      31           0           1        1         1                0   \n",
      "..    ...         ...         ...      ...       ...              ...   \n",
      "297    30           1           1        1         1                0   \n",
      "298    30           1           0        0         1                0   \n",
      "299    24           1           0        0         1                0   \n",
      "300    18           1           0        0         1                0   \n",
      "301    30           1           0        0         1                0   \n",
      "\n",
      "     ip_failure  ip_success  no_failure  first    td        ts  target  \\\n",
      "0            31           0          31      0     3 -1.885636       1   \n",
      "1             6           2           8      0  1351  0.511426       1   \n",
      "2             5           1          12      0   785  0.517304       1   \n",
      "3             7           2           9      0   231  0.524751       1   \n",
      "4             8           1          11      0     7  0.516337       1   \n",
      "..          ...         ...         ...    ...   ...       ...     ...   \n",
      "297           3           2           4      0     1  0.511124       0   \n",
      "298           0           4           0      0    26  0.512363       0   \n",
      "299           0           9           0      0     9  0.538242       0   \n",
      "300           0          33           0      0     8  0.540250       0   \n",
      "301           0          12           0      0    33  0.511790       0   \n",
      "\n",
      "       source  \n",
      "0       smote  \n",
      "1    original  \n",
      "2       smote  \n",
      "3       smote  \n",
      "4       smote  \n",
      "..        ...  \n",
      "297  original  \n",
      "298  original  \n",
      "299  original  \n",
      "300  original  \n",
      "301  original  \n",
      "\n",
      "[302 rows x 14 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user  is_private  is_failure  is_root  is_valid  not_valid_count  \\\n",
      "0      18           1           1        0         0               15   \n",
      "1      44           1           1        1         0               17   \n",
      "2       3           1           1        0         0               21   \n",
      "3      30           0           1        0         0               10   \n",
      "4      28           1           1        0         0                2   \n",
      "..    ...         ...         ...      ...       ...              ...   \n",
      "297    30           1           1        1         1                0   \n",
      "298    30           1           0        0         1                0   \n",
      "299    24           1           0        0         1                0   \n",
      "300    18           1           0        0         1                0   \n",
      "301    30           1           0        0         1                0   \n",
      "\n",
      "     ip_failure  ip_success  no_failure  first    td        ts  target  \\\n",
      "0            42           2          12      0     1 -0.781321       1   \n",
      "1            17           0          42      0  1351 -0.781323       1   \n",
      "2            12           1          19      0  1803 -0.781320       1   \n",
      "3             5           0          25      0   285  1.286202       1   \n",
      "4            12           0          45      0    42  1.274471       1   \n",
      "..          ...         ...         ...    ...   ...       ...     ...   \n",
      "297           3           2           4      0     1  0.511124       0   \n",
      "298           0           4           0      0    26  0.512363       0   \n",
      "299           0           9           0      0     9  0.538242       0   \n",
      "300           0          33           0      0     8  0.540250       0   \n",
      "301           0          12           0      0    33  0.511790       0   \n",
      "\n",
      "       source  \n",
      "0         gan  \n",
      "1         gan  \n",
      "2         gan  \n",
      "3         gan  \n",
      "4         gan  \n",
      "..        ...  \n",
      "297  original  \n",
      "298  original  \n",
      "299  original  \n",
      "300  original  \n",
      "301  original  \n",
      "\n",
      "[302 rows x 14 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user  is_private  is_failure  is_root  is_valid  not_valid_count  \\\n",
      "0      31           1           1        0         0                7   \n",
      "1      33           1           1        0         0                7   \n",
      "2      30           1           1        0         0               13   \n",
      "3      14           1           1        0         0                5   \n",
      "4      28           1           1        0         0               10   \n",
      "..    ...         ...         ...      ...       ...              ...   \n",
      "297    30           1           1        1         1                0   \n",
      "298    30           1           0        0         1                0   \n",
      "299    24           1           0        0         1                0   \n",
      "300    18           1           0        0         1                0   \n",
      "301    30           1           0        0         1                0   \n",
      "\n",
      "     ip_failure  ip_success  no_failure  first    td        ts  target  \\\n",
      "0             7           0           7      0     3 -1.885643       1   \n",
      "1            10           8           8      0  1144  0.527845       1   \n",
      "2            13          13           8      0  1774  0.538558       1   \n",
      "3             6           4          10      0   643  0.529958       1   \n",
      "4            12          11           8      0  1405  0.536448       1   \n",
      "..          ...         ...         ...    ...   ...       ...     ...   \n",
      "297           3           2           4      0     1  0.511124       0   \n",
      "298           0           4           0      0    26  0.512363       0   \n",
      "299           0           9           0      0     9  0.538242       0   \n",
      "300           0          33           0      0     8  0.540250       0   \n",
      "301           0          12           0      0    33  0.511790       0   \n",
      "\n",
      "               source  \n",
      "0    borderline smote  \n",
      "1    borderline smote  \n",
      "2    borderline smote  \n",
      "3    borderline smote  \n",
      "4    borderline smote  \n",
      "..                ...  \n",
      "297          original  \n",
      "298          original  \n",
      "299          original  \n",
      "300          original  \n",
      "301          original  \n",
      "\n",
      "[302 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "#KM = KMeans(n_clusters=(int)((count1+count2)/2))\n",
    "\n",
    "centroids_rows_ = {\n",
    "    \"mix\": {},\n",
    "    \"smote\": {},\n",
    "    \"GAN\": {},\n",
    "    \"borderline\": {}\n",
    "}\n",
    "\n",
    "centroids_ = {}\n",
    "\n",
    "results_KM_SWAP_ = {\n",
    "    \"mix\": {},\n",
    "    \"smote\": {},\n",
    "    \"GAN\": {},\n",
    "    \"borderline\": {}\n",
    "}\n",
    "\n",
    "results_ = {}\n",
    "df_ = {}\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "     # klasteryzacja dotyczy tylko jednego ze zbiorow drugi jest przepisywany\n",
    "    X_majority = X_train[y_train == 1]\n",
    "    X_minority = X_train[y_train == 0]\n",
    "    \n",
    "    kmeans = KM.fit(X_majority)\n",
    "    \n",
    "    #centroids\n",
    "    for i in range ((int)((count1+count2)/2)):\n",
    "        rows_in_cluster = X_majority[kmeans.labels_ == i] \n",
    "        centroids_rows_[name][i] = rows_in_cluster\n",
    "        \n",
    "        centroids_ = pd.DataFrame(kmeans.cluster_centers_, columns=X_train.columns)\n",
    "    \n",
    "    #results_KM_SWAP_ = {}\n",
    "    \n",
    "    \n",
    "    for i in range(len(centroids_)):\n",
    "        if (len(centroids_rows_[name][i])>1):\n",
    "            dist_={}\n",
    "            index_ = {}\n",
    "            centroid = centroids_.iloc[i]\n",
    "            for j in range(len(centroids_rows_[name][i])):\n",
    "                index_ = list(centroids_rows_[name][i].index)\n",
    "                row = centroids_rows_[name][i].iloc[j]\n",
    "                index_map = {j: idx for j, idx in enumerate(index_)}\n",
    "                dist_[j] = euclidean(centroid, row)         #tworze slwonik wartosci\n",
    "                \n",
    "            min_key = min(dist_, key=dist_.get)\n",
    "            results_KM_SWAP_[name][i] = centroids_rows_[name][i].iloc[[min_key]]\n",
    "            \n",
    "        else:\n",
    "            results_KM_SWAP_[name][i] = centroids_rows_[name][i].iloc[[0]]\n",
    "        \n",
    "        results_[name] = pd.concat(results_KM_SWAP_[name].values(), ignore_index=True)    \n",
    "        \n",
    "    df_y_majority = pd.Series([1] * (int)((count1+count2)/2), name=\"target\") \n",
    "    df_majority = pd.concat([results_[name], df_y_majority], axis=1).reset_index(drop=True)\n",
    "        \n",
    "     \n",
    "    df_X_minority = X_minority.reset_index(drop=True)\n",
    "    df_y_minority = pd.Series([0] * len(X_minority), name=\"target\")\n",
    "    df_miniority = pd.concat([df_X_minority, df_y_minority], axis=1).reset_index(drop=True)\n",
    "\n",
    "    df_[name] = pd.concat([df_majority, df_miniority], axis=0).reset_index(drop=True)  \n",
    "    \n",
    "    #copy source from sum_all_data \n",
    "    columns_ = list(df_[name].columns.values)\n",
    "    df_[name] = df_[name].merge(sum_all_data, on=columns_, how=\"left\")\n",
    "    print(df_[name])  \n",
    "    \n",
    "    df_[name].to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_KM_NN_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fabb30",
   "metadata": {},
   "source": [
    "#### K-means + cosinus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e10684",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_rows_ = {\n",
    "    \"mix\": {},\n",
    "    \"smote\": {},\n",
    "    \"GAN\": {},\n",
    "    \"borderline\": {}\n",
    "}\n",
    "\n",
    "centroids_ = {}\n",
    "\n",
    "results_KM_SWAP_ = {\n",
    "    \"mix\": {},\n",
    "    \"smote\": {},\n",
    "    \"GAN\": {},\n",
    "    \"borderline\": {}\n",
    "}\n",
    "\n",
    "results_ = {}\n",
    "df_ = {}\n",
    "\n",
    "for (name, (X_train, y_train)), (_, compare_df) in zip(data.items(), compare.items()):\n",
    "     # klasteryzacja dotyczy tylko jednego ze zbiorow drugi jest przepisywany\n",
    "    X_majority = X_train[y_train == 1]\n",
    "    X_minority = X_train[y_train == 0]\n",
    "    \n",
    "    kmeans = KM.fit(X_majority)\n",
    "    \n",
    "    #centroids\n",
    "    for i in range ((int)((count1+count2)/2)):\n",
    "        rows_in_cluster = X_majority[kmeans.labels_ == i] \n",
    "        centroids_rows_[name][i] = rows_in_cluster\n",
    "        \n",
    "        centroids_ = pd.DataFrame(kmeans.cluster_centers_, columns=X_train.columns)\n",
    "    \n",
    "    #results_KM_SWAP_ = {}\n",
    "    \n",
    "    \n",
    "    for i in range(len(centroids_)):\n",
    "        if (len(centroids_rows_[name][i])>1):\n",
    "            dist_={}\n",
    "            index_ = {}\n",
    "            centroid = centroids_.iloc[i]\n",
    "            for j in range(len(centroids_rows_[name][i])):\n",
    "                index_ = list(centroids_rows_[name][i].index)\n",
    "                row = centroids_rows_[name][i].iloc[j]\n",
    "                #index_ = { \"index_rows\": j, \"index_centroid\": list(centroids_rows_[name][i].index) } #tworze slwonik wartosci\n",
    "                index_map = {j: idx for j, idx in enumerate(index_)}\n",
    "                \n",
    "                #print(index_)\n",
    "                dist_[j] = euclidean(centroid, row)         #tworze slwonik wartosci\n",
    "                \n",
    "            #print(index_map)    \n",
    "            min_key = min(dist_, key=dist_.get)\n",
    "            #print(min_key)\n",
    "            #new_cent = index_.get\n",
    "            results_KM_SWAP_[name][i] = centroids_rows_[name][i].iloc[[min_key]]\n",
    "            \n",
    "            #print(results_KM_SWAP_[i])\n",
    "            \n",
    "            #results_KM_SWAP_[i] = dist_.iloc[min_index]\n",
    "            #print(dist_[0])\n",
    "        else:\n",
    "            results_KM_SWAP_[name][i] = centroids_rows_[name][i].iloc[[0]]\n",
    "        \n",
    "        results_[name] = pd.concat(results_KM_SWAP_[name].values(), ignore_index=True)    \n",
    "        #results_KM_SWAP_[name][i][\"target\"] = 1      \n",
    "        #results_KM_SWAP_[name][i][\"source\"] = None\n",
    "        #print(results_KM_SWAP_[name])    \n",
    "    \n",
    "    \n",
    "    \"\"\" for key in [\"mix\", \"smote\", \"GAN\", \"borderline\"]:\n",
    "        df_[name] = pd.DataFrame.from_dict(results_KM_SWAP_[name], orient=\"index\")        \"\"\"   \n",
    "\n",
    "    \n",
    "        \n",
    "    df_y_majority = pd.Series([1] * (int)((count1+count2)/2), name=\"target\") \n",
    "    df_majority = pd.concat([results_[name], df_y_majority], axis=1).reset_index(drop=True)\n",
    "        \n",
    "    #print(df_majority)        \n",
    "    df_X_minority = X_minority.reset_index(drop=True)\n",
    "    df_y_minority = pd.Series([0] * len(X_minority), name=\"target\")\n",
    "    df_miniority = pd.concat([df_X_minority, df_y_minority], axis=1).reset_index(drop=True)\n",
    "    #print(df_miniority)\n",
    "        #print(df_[name])\n",
    "    df_[name] = pd.concat([df_majority, df_miniority], axis=0).reset_index(drop=True)  \n",
    "    \n",
    "    #copy source from sum_all_data \n",
    "    columns_ = list(df_[name].columns.values)\n",
    "    df_[name] = df_[name].merge(sum_all_data, on=columns_, how=\"left\")\n",
    "    print(df_[name])  \n",
    "    \n",
    "    df_[name].to_csv(f\"D:\\\\ml\\\\undersampling_data\\\\data\\\\ssh\\\\reduced\\\\{name}_KM_cos_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22453c6",
   "metadata": {},
   "source": [
    "#### K-means + cosinus + distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662c186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a41c0c4d",
   "metadata": {},
   "source": [
    "#### DBSCAN + distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf27ed5",
   "metadata": {},
   "source": [
    "#### DBSCAN + cosinus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb4069",
   "metadata": {},
   "source": [
    "#### K-means (resampling = calculate by DBSCAN) + centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd23ab46",
   "metadata": {},
   "source": [
    "#### K-means (resampling = calculate by DBSCAN) + the nearest neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c243f5b",
   "metadata": {},
   "source": [
    "#### K-means (resampling = calculate by DBSCAN) + cosinus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c152cd",
   "metadata": {},
   "source": [
    "#### K-means (resampling = calculate by DBSCAN) + cosinus + distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
